import pandas as pd
import re
import nltk
import html
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from nltk.corpus import wordnet
from nltk.tokenize import word_tokenize
import language_tool_python
import language_tool_python.utils


df = pd.read_csv("youtube_comments20.csv", sep=';')

df.drop_duplicates(inplace=True)


tool = language_tool_python.LanguageTool('en-US')

# Function to correct text
def correct_text(text):
    matches = tool.check(text)
    return language_tool_python.utils.correct(text, matches)

def get_wordnet_pos(treebank_tag):
    if treebank_tag.startswith('J'):
        return 'a'  # adjective
    elif treebank_tag.startswith('V'):
        return 'v'  # verb
    elif treebank_tag.startswith('N'):
        return 'n'  # noun
    elif treebank_tag.startswith('R'):
        return 'r'  # adverb
    else:
        return None  # No mapping available
    
def clean_text(text):
    if pd.isna(text):
        return ""  # Return empty string for NaN values
    
    text = re.sub(r'&#39', "", text)
    text = re.sub(r'&#39;s', " is", text)
    text = re.sub(r'Ã¡', "a", text)
    text = re.sub(r'\bs.\b', '.', text)
    text = re.sub(r'\bs\b', '', text)
    # Remove usernames
    text = re.sub(r'@+[\w-]+\b', '', text)
    
    # HTML decoding
    text = html.unescape(text)
    
    # Remove URLs
    text = re.sub(r'http\S+|www\S+', '', text)

    text = re.sub(r'<br>', ' ', text)
    text = re.sub(r'<b>', ' ', text)
    text = re.sub(r'</b>', ' ', text)
    text = re.sub(r'<>', ' ', text)
    text = re.sub(r'<i>', ' ', text)
    text = re.sub(r'</i>', ' ', text)
    text = re.sub(r'&gt', ' ', text)
    text = re.sub(r'sÃ³', '', text)
    text = re.sub(r'T<br>', '', text)
    text = re.sub(r'<del>', ' ', text)
    text = re.sub(r'Pr*stit*te', 'Prostitute', text)


    # Remove non-ASCII characters
    text = re.sub(r'[^\x00-\x7F]+', ' ', text)

    # Replace HTML character codes with ASCII equivalent
    replacements = {
        "Its": "It is",
        "its": "it is",
        "39": "'",
        r"quot": "",
        "a href ": "",
        "MM": "M"
        # Add more replacements as needed
    }
    for pattern, replacement in replacements.items():
        text = text.replace(pattern, replacement)

    text = correct_text(text)

    abbreviations = {
    "imo": "in my opinion",
    "imho": "in my humble opinion",
    "iirc": "if I recall correctly",
    "btw": "by the way",
    "afaik": "as far as I know",
    "fwiw": "for what it's worth",
    "omg": "oh my god",
    "brb": "be right back",
    "btw": "by the way",
    "afk": "away from keyboard",
    "idk": "I don't know",
    "fyi": "for your information",
    "tbh": "to be honest",
    "wtf": "what the fuck",
    "wth": "what the hell",
    "nvm": "never mind",
    "ttyl": "talk to you later",
    "tmi": "too much information",
    "smh": "shaking my head",
    "rofl": "rolling on the floor laughing",
    "lmao": "laughing my ass off",
    "gtg": "got to go",
    "thx": "thanks",
    "ty": "thank you",
    "yw": "you're welcome",
    "np": "no problem",
    "hmu": "hit me up",
    "irl": "in real life",
    "icymi": "in case you missed it",
    "ootd": "outfit of the day",
    "tbt": "throwback Thursday",
    "fbf": "flashback Friday",
    "tgif": "thank god it's Friday",
    "fomo": "fear of missing out",
    "imo": "in my opinion",
    "imho": "in my humble opinion",
    "ic": "I see",
    "irl": "in real life",
    "gg": "good game",
    "ggwp": "good game, well played",
    "glhf": "good luck, have fun",
    "gl": "good luck",
    "gg ez": "good game, easy",
    "brb": "be right back",
    "bbl": "be back later",
    "g2g": "got to go",
    "ggs": "good games",
    "idc": "I don't care",
    "idgaf": "I don't give a fuck",
    "idk": "I don't know",
    "ttyl": "talk to you later",
    "lol": "laugh out loud",
    "lul": "laugh out loud",
    "lmao": "laugh my ass off",
    "lmfao": "laugh my fucking ass off",
    "omg": "oh my god",
    "omfg": "oh my fucking god",
    "wtf": "what the fuck",
    "stfu": "shut the fuck up",
    "smh": "shake my head",
    "imo": "in my opinion",
    "imho": "in my humble opinion",
    "fyi": "for your information",
    "btw": "by the way",
    "thx": "thanks",
    "np": "no problem",
    "yw": "you're welcome",
    "ikr": "I know, right?",
    "bff": "best friends forever",
    "brb": "be right back",
    "afaik": "as far as I know",
    "asap": "as soon as possible",
    "diy": "do it yourself",
    "fml": "fuck my life",
    "gtg": "got to go",
    "hmu": "hit me up",
    "idc": "I don't care",
    "idk": "I don't know",
    "irl": "in real life",
    "jk": "just kidding",
    "lmk": "let me know",
    "nvm": "never mind",
    "omg": "oh my god",
    "pov": "point of view",
    "tbh": "to be honest",
    "ttyl": "talk to you later",
    "wtf": "what the fuck",
    "yw": "you're welcome",
    "b2b": "business to business",
    "b2c": "business to consumer",
    "crm": "customer relationship management",
    "cto": "chief technology officer",
    "seo": "search engine optimization",
    "saas": "software as a service",
    "api": "application programming interface",
    "ui": "user interface",
    "ux": "user experience",
    "html": "hypertext markup language",
    "css": "cascading style sheets",
    "js": "javascript",
    "sql": "structured query language",
    "aws": "amazon web services",
    "gis": "geographic information system",
    "iot": "internet of things",
    "crm": "customer relationship management",
    "ml": "machine learning",
    "ai": "artificial intelligence",
    "nlp": "natural language processing",
    "vr": "virtual reality",
    "ar": "augmented reality",
    "ui/ux": "user interface/user experience",
    "b2b": "business to business",
    "b2c": "business to consumer",
    "roi": "return on investment",
    "kpi": "key performance indicator",
    "bpm": "business process management",
    "pos": "point of sale",
    "erp": "enterprise resource planning",
    "crm": "customer relationship management",
    "cms": "content management system",
    "ppc": "pay per click",
    "cpc": "cost per click",
    "ctr": "click through rate",
    "roi": "return on investment",
    "sem": "search engine marketing",
    "seo": "search engine optimization",
    "smm": "social media marketing",
    "ppc": "pay per click",
    "cpc": "cost per click",
    "ctr": "click through rate",
    "roi": "return on investment",
    "ppp": "pay per post",
    "ppm": "pay per mille",
    "ppa": "pay per action",
    "b2b": "business to business",
    "b2c": "business to consumer",
    "roi": "return on investment",
    "cpm": "cost per mille",
    "cpa": "cost per action",
    "cpv": "cost per view",
    "cpt": "cost per thousand",
    "cm": "community manager",
    "smm": "social media manager",
    "cpc": "cost per click",
    "ctr": "click through rate",
    "crm": "customer relationship management",
    "saas": "software as a service",
    "qa": "quality assurance",
    "ui": "user interface",
    "ux": "user experience",
    "bi": "business intelligence",
    "cms": "content management system",
    "seo": "search engine optimization",
    "sem": "search engine marketing",
    "ppc": "pay per click",
    "cpc": "cost per click",
    "ctr": "click through rate",
    "roi": "return on investment",
    "ppa": "pay per action",
    "cpm": "cost per mille",
    "cpv": "cost per view",
    "smm": "social media marketing",
    "orm": "online reputation management",
    "lms": "learning management system",
    "erp": "enterprise resource planning",
    "hrm": "human resource management",
    "eom": "end of message",
    "np": "no problem",
    "tia": "thanks in advance",
    "afaik": "as far as I know",
    "a.k.a.": "also known as",
    "e.g.": "for example",
    "i.e.": "that is",
    "p.s.": "postscript",
    "w/": "with",
    "w/o": "without",
    "u": "you",
    "ur": "your",
    "n": "and",
    "c": "see",
    "k": "okay",
    "tho": "though",
    "r": "are",
    "yr": "year",
    "yr": "your",
    "yrs": "years",
    "w/": "with",
    "w/o": "without",
    "b/c": "because",
    "y": "why",
    "r": "are",
    "u": "you",
    "c": "see",
    "k": "okay",
    "tho": "though",
    "wut": "what",
    "lemme": "let me",
    "gimme": "give me",
    "gonna": "going to",
    "wanna": "want to",
    "kinda": "kind of",
    "sorta": "sort of",
    "cos": "because",
    "coz": "because",
    "cuz": "because",
    "luv": "love",
    "thx": "thanks",
    "pls": "please",
    "plz": "please",
    "sry": "sorry",
    "msg": "message",
    "txt": "text",
    "gf": "girlfriend",
    "bf": "boyfriend",
    "bff": "best friends forever",
    "lmao": "laugh my ass off",
    "lmfao": "laugh my fucking ass off",
    "rofl": "rolling on the floor laughing",
    "brb": "be right back",
    "bbl": "be back later",
    "gtg": "got to go",
    "ttyl": "talk to you later",
    "thx": "thanks",
    "k": "okay",
    "np": "no problem",
    "yw": "you're welcome",
    "omw": "on my way",
    "hmu": "hit me up",
    "idk": "I don't know",
    "wut": "what",
    "whatcha": "what are you",
    "gonna": "going to",
    "gotta": "got to",
    "hafta": "have to",
    "wanna": "want to",
    "dunno": "don't know",
    "coulda": "could have",
    "shoulda": "should have",
    "woulda": "would have",
    "mighta": "might have",
    "kinda": "kind of",
    "sorta": "sort of",
    "cuz": "because",
    "cos": "because",
    "b4": "before",
    "r": "are",
    "u": "you",
    "m8": "mate",
    "txt": "text",
    "msg": "message",
    "pls": "please",
    "plz": "please",
    "btw": "by the way",
    "imo": "in my opinion",
    "imho": "in my humble opinion",
    "ic": "I see",
    "idc": "I don't care",
    "idgaf": "I don't give a fuck",
    "idk": "I don't know",
    "irl": "in real life",
    "jk": "just kidding",
    "lmao": "laugh my ass off",
    "lmfao": "laugh my fucking ass off",
    "nvm": "never mind",
    "omg": "oh my god",
    "pov": "point of view",
    "tbh": "to be honest",
    "ttyl": "talk to you later",
    "wtf": "what the fuck",
    "yw": "you're welcome",
    "U": "You",
    "u": "you",
    "Isnt": "Is not",
    "isnt": "Is not",
    "Isn t": "Is not",
    "isn t": "Is not",
    "dw": "don't worry",
    "JERBS": "JOBS",
    "jerbs": "jobs",
    "JERB": "JOB",
    "jerb": "job",
    "JURBS": "JOBS",
    "jurbs": "jobs",
    "JURB": "JOB",
    "jurb": "job",
    "dey": "they",
    "tuk": "took",
    "er": "our",
    "same": "our",
    "ks": "is",
    "reslly": "really",
    "schoolchildren": "school children",
    "BS": "bull shit",
    "bs": "bull shit",
    "Bs": "bull shit",
    "CIAfunds" : "CIA funds",
    "invthe" : "in the",
    "mgmt" : "management",
    "Don't" : "do not",
    "7months" : "7 months",
    "showes" : "shows",
    "Lol" : "laughing out loud",
    "ppl" : "people",
    "menagment" : "management",
    "dew" : "due",
    "wonan" : "woman",
    "ORF" : "of",
    "incharge" : "in charge",
    "mathmatical" : "mathematical",
    "colapse" : "collapse",
    "replacrd" : "replaced",
    "creative er" : "more creative",
    "signle" : "single",
    "suxh" : "such",
    "anount" : "amount",
    "Wont ": "will not",
    "wont ": "will not",
    }

    for word, replacement in abbreviations.items():
    # Create a regular expression pattern to match the whole word
        pattern = r'\b' + re.escape(word) + r'\b'
        # Replace the abbreviation with its expanded form using the regular expression
        text = re.sub(pattern, replacement, text)

    # Replace specific contractions and common phrases
    contractions = {
    "'s": " is",
    "'m": " am",
    "'re": " are",
    "'ve": " have",
    "'ll": " will",
    "can't": "can not",
    "couldn't": "could not",
    "don't": "do not",
    "doesn't": "does not",
    "won't": "will not",
    "haven't": "have not",
    "hasn't": "has not",
    "I'm": "I am",
    "I've": "I have",
    "I'll": "I will",
    "it's": "it is",
    "let's": "let us",
    "you're": "you are",
    "you've": "you have",
    "you'll": "you will",
    "he's": "he is",
    "he'll": "he will",
    "she's": "she is",
    "she'll": "she will",
    "we're": "we are",
    "we've": "we have",
    "we'll": "we will",
    "they're": "they are",
    "they've": "they have",
    "they'll": "they will",
    "I'd": "I would",
    "you'd": "you would",
    "he'd": "he would",
    "she'd": "she would",
    "we'd": "we would",
    "they'd": "they would",
    "that's": "that is",
    "what's": "what is",
    "who's": "who is",
    "how's": "how is",
    "where's": "where is",
    "when's": "when is",
    "why's": "why is",
    "it'll": "it will",
    "isn't": "is not",
    "aren't": "are not",
    "wasn't": "was not",
    "weren't": "were not",
    "haven't": "have not",
    "hasn't": "has not",
    "hadn't": "had not",
    "won't": "will not",
    "wouldn't": "would not",
    "don't": "do not",
    "doesn't": "does not",
    "didn't": "did not",
    "can t": "can not",
    "cannot": "can not",
    "couldn t": "could not",
    "mustn t": "must not",
    "shouldn t": "should not",
    "shan t": "shall not",
    "let s": "let us",
    "that ll": "that will",
    "there s": "there is",
    "here s": "here is",
    "what ll": "what will",
    "what re": "what are",
    "what s": "what is",
    "what ve": "what have",
    "who s": "who is",
    "who ll": "who will",
    "who d": "who would",
    "who ve": "who have",
    "why s": "why is",
    "why ll": "why will",
    "why d": "why did",
    "why ve": "why have",
    "how s": "how is",
    "how ll": "how will",
    "how d": "how did",
    "how ve": "how have",
    "Can t": "can not",
    "Couldn t": "could not",
    "Don t": "do not",
    "Doesn t": "does not",
    "Won t": "will not",
    "Haven t": "have not",
    "Hasn t": "has not",
    "I m": "I am",
    "I ve": "I have",
    "I ll": "I will",
    "It s": "it is",
    "Let s": "let us",
    "You re": "you are",
    "You ve": "you have",
    "You ll": "you will",
    "He s": "he is",
    "He ll": "he will",
    "She s": "she is",
    "She ll": "she will",
    "We re": "we are",
    "We ve": "we have",
    "We ll": "we will",
    "They re": "they are",
    "They ve": "they have",
    "They ll": "they will",
    "I d": "I would",
    "You d": "you would",
    "He d": "he would",
    "She d": "she would",
    "We d": "we would",
    "They d": "they would",
    "That s": "that is",
    "What s": "what is",
    "Who s": "who is",
    "How s": "how is",
    "Where s": "where is",
    "When s": "when is",
    "Why s": "why is",
    "It ll": "it will",
    "Isn t": "is not",
    "Aren t": "are not",
    "Wasn t": "was not",
    "Weren t": "were not",
    "Haven t": "have not",
    "Hasn t": "has not",
    "Hadn t": "had not",
    "Won t": "will not",
    "Wouldn t": "would not",
    "Don t": "do not",
    "Doesn t": "does not",
    "Didn t": "did not",
    "Can t": "can not",
    "Cannot": "can not",
    "Couldn t": "could not",
    "Mustn t": "must not",
    "Shouldn t": "should not",
    "Shan t": "shall not",
    "Let s": "let us",
    "That ll": "that will",
    "There s": "there is",
    "Here s": "here is",
    "What ll": "what will",
    "What re": "what are",
    "What s": "what is",
    "What ve": "what have",
    "Who s": "who is",
    "Who ll": "who will",
    "Who d": "who would",
    "Who ve": "who have",
    "Why s": "why is",
    "Why ll": "why will",
    "Why d": "why did",
    "Why ve": "why have",
    "How s": "how is",
    "How ll": "how will",
    "How d": "how did",
    "How ve": "how have",
    "can t": "can not",
    "couldn t": "could not",
    "don t": "do not",
    "doesn t": "does not",
    "won t": "will not",
    "haven t": "have not",
    "hasn t": "has not",
    "I m": "I am",
    "I ve": "I have",
    "I ll": "I will",
    "it s": "it is",
    "let s": "let us",
    "you re": "you are",
    "you ve": "you have",
    "you ll": "you will",
    "he s": "he is",
    "he ll": "he will",
    "she s": "she is",
    "she ll": "she will",
    "we re": "we are",
    "we ve": "we have",
    "we ll": "we will",
    "they re": "they are",
    "they ve": "they have",
    "they ll": "they will",
    "I d": "I would",
    "you d": "you would",
    "he d": "he would",
    "she d": "she would",
    "we d": "we would",
    "they d": "they would",
    "that s": "that is",
    "what s": "what is",
    "who s": "who is",
    "hows": "how is",
    "where s": "where is",
    "when s": "when is",
    "why s": "why is",
    "it ll": "it will",
    "isn t": "is not",
    "aren t": "are not",
    "wasn t": "was not",
    "weren t": "were not",
    "haven t": "have not",
    "hasn t": "has not",
    "hadn t": "had not",
    "won t": "will not",
    "wouldn t": "would not",
    "don t": "do not",
    "doesn t": "does not",
    "didn t": "did not",
    "can t": "can not",
    "cannot": "can not",
    "couldn t": "could not",
    "mustn t": "must not",
    "shouldn t": "should not",
    "shan t": "shall not",
    "let s": "let us",
    "that ll": "that will",
    "there s": "there is",
    "here s": "here is",
    "what ll": "what will",
    "what re": "what are",
    "what s": "what is",
    "what ve": "what have",
    "who s": "who is",
    "who ll": "who will",
    "who d": "who would",
    "who ve": "who have",
    "why s": "why is",
    "why ll": "why will",
    "why d": "why did",
    "why ve": "why have",
    "how s": "how is",
    "how ll": "how will",
    "how d": "how did",
    "how ve": "how have",
    "Can t": "can not",
    "Couldn t": "could not",
    "Don t": "do not",
    "Doesn t": "does not",
    "Won t": "will not",
    "Haven t": "have not",
    "Hasn t": "has not",
    "I m": "I am",
    "I ve": "I have",
    "I ll": "I will",
    "It s": "it is",
    "Let s": "let us",
    "You re": "you are",
    "You ve": "you have",
    "You ll": "you will",
    "He s": "he is",
    "He ll": "he will",
    "She s": "she is",
    "She ll": "she will",
    "We re": "we are",
    "We ve": "we have",
    "We ll": "we will",
    "They re": "they are",
    "They ve": "they have",
    "They ll": "they will",
    "I d": "I would",
    "You d": "you would",
    "He d": "he would",
    "She d": "she would",
    "We d": "we would",
    "They d": "they would",
    "That s": "that is",
    "What s": "what is",
    "Who s": "who is",
    "How s": "how is",
    "Where s": "where is",
    "When s": "when is",
    "Why s": "why is",
    "It ll": "it will",
    "Isn t": "is not",
    "Aren t": "are not",
    "Wasn t": "was not",
    "Weren t": "were not",
    "Haven t": "have not",
    "Hasn t": "has not",
    "Hadn t": "had not",
    "Won t": "will not",
    "Wouldn t": "would not",
    "Don t": "do not",
    "Doesn t": "does not",
    "Didn t": "did not",
    "Can t": "can not",
    "Cannot": "can not",
    "Couldn t": "could not",
    "Mustn t": "must not",
    "Shouldn t": "should not",
    "Shan t": "shall not",
    "Let s": "let us",
    "That ll": "that will",
    "There s": "there is",
    "Here s": "here is",
    "What ll": "what will",
    "What re": "what are",
    "What s": "what is",
    "What ve": "what have",
    "Who s": "who is",
    "Who ll": "who will",
    "Who d": "who would",
    "Who ve": "who have",
    "Why s": "why is",
    "Why ll": "why will",
    "Why d": "why did",
    "Why ve": "why have",
    "How s": "how is",
    "How ll": "how will",
    "How d": "how did",
    "How ve": "how have",
    "Yall": "You all",
    "everybodys": "everybody's",
    "Cant ": "can not",
    "cant ": "can not",
    "Couldnt ": "could not",
    "couldnt ": "could not",
    "Dont ": "do not",
    "dont ": "do not",
    "Doesnt ": "does not",
    "doesnt ": "does not",
    "Wont ": "will not",
    "wont ": "will not",
    "Havent ": "have not",
    "havent ": "have not",
    "Hasnt ": "has not",
    "hasnt ": "has not",
    "Lets ": "let us",
    "lets ": "let us",
    "Youre ": "you are",
    "youre ": "you are",
    "Youve ": "you have",
    "youve ": "you have",
    "Youll ": "you will",
    "youll ": "you will",
    "Hes ": "he is",
    "hes ": "he is",
    "Hell ": "he will",
    "hell ": "he will",
    "Shes ": "she is",
    "shes ": "she is",
    "Shell ": "she will",
    "shell ": "she will",
    "Weve ": "we have",
    "weve ": "we have",
    "Theyre ": "they are",
    "theyre ": "they are",
    "Theyve ": "they have",
    "theyve ": "they have",
    "Theyll ": "they will",
    "theyll ": "they will",
    "Youd ": "you would",
    "youd ": "you would",
    "Hed ": "he would",
    "hed ": "he would",
    "Shed ": "she would",
    "shed ": "she would",
    "Wed ": "we would",
    "wed ": "we would",
    "Theyd ": "they would",
    "theyd ": "they would",
    "Thats ": "that is",
    "thats ": "that is",
    "Whats ": "what is",
    "whats ": "what is",
    "Whos ": "who is",
    "whos ": "who is",
    "Hows ": "how is",
    "hows ": "how is",
    "Wheres ": "where is",
    "wheres ": "where is",
    "Whens ": "when is",
    "whens ": "when is",
    "Whys ": "why is",
    "whys ": "why is",
    "Itll ": "it will",
    "itll ": "it will",
    "Isnt ": "is not",
    "isnt ": "is not",
    "Arent ": "are not",
    "arent ": "are not",
    "Wasnt ": "was not",
    "wasnt ": "was not",
    "Werent ": "were not",
    "werent ": "were not",
    "Havent ": "have not",
    "havent ": "have not",
    "Hasnt ": "has not",
    "hasnt ": "has not",
    "Hadnt ": "had not",
    "hadnt ": "had not",
    "Wouldnt ": "would not",
    "wouldnt ": "would not",
    "Dont ": "do not",
    "dont ": "do not",
    "Doesnt ": "does not",
    "doesnt ": "does not",
    "Didnt ": "did not",
    "didnt ": "did not",
    "Cant ": "can not",
    "cant ": "can not",
    "Cannot ": "can not",
    "cannot ": "can not",
    "Couldnt ": "could not",
    "couldnt ": "could not",
    "Mustnt ": "must not",
    "mustnt ": "must not",
    "Shouldnt ": "should not",
    "shouldnt ": "should not",
    "Shant ": "shall not",
    "shant ": "shall not",
    "Lets ": "let us",
    "lets ": "let us",
    "Thatll ": "that will",
    "thatll ": "that will",
    "Theres ": "there is",
    "theres ": "there is",
    "Heres ": "here is",
    "heres ": "here is",
    "Whatll ": "what will",
    "whatll ": "what will",
    "Whatre ": "what are",
    "whatre ": "what are",
    "Whats ": "what is",
    "whats ": "what is",
    "Whatve ": "what have",
    "whatve ": "what have",
    "Wholl ": "who will",
    "wholl ": "who will",
    "Whod ": "who would",
    "whod ": "who would",
    "Whove ": "who have",
    "whove ": "who have",
    "Whys ": "why is",
    "whys ": "why is",
    "Whyll ": "why will",
    "whyll ": "why will",
    "Whyd ": "why did",
    "whyd ": "why did",
    "Whyve ": "why have",
    "whyve ": "why have",
    "Hows ": "how is",
    "hows ": "how is",
    "Howll ": "how will",
    "howll ": "how will",
    "Howd ": "how did",
    "howd ": "how did",
    "Howve ": "how have",
    "howve ": "how have",
    "Id ": "I would",
    "id ": "I would",
    "Im ": "I am",
    "im ": "I am",
    "Ive ": "I have",
    "ive ": "I have",
    "Ill ": "I will",
    "ill ": "I will",
    "Its ": "it is",
    "its": "it is",
    "idk": "i do not know",
    "Idk": "i do not know",
    "dafuq": "the fuck",
    "Dafuq": "the fuck",
    "wtf": "what the fuck",
    "Wtf": "what the fuck",
    "WTF": "what the fuck",
    "omlllll" : "oh my lord",
    "oml" : "oh my lord",
    "replased" : "replaced",
    "ER" : "OUR",
    "TERK" : "TOOK",
    "withy" : "with",
    "commnts" : "comments",
    "offnse" : " offense"
    }

    #for contraction, expanded in contractions.items():
    #    text = text.replace(contraction, expanded)

    for contraction, expanded in contractions.items():
    # Create a regular expression pattern to match the whole word
        pattern = r'\b' + re.escape(contraction) + r'\b'
        # Replace the abbreviation with its expanded form using the regular expression
        text = re.sub(pattern, expanded + ' ', text)

    # Remove any remaining non-word characters except for apostrophes, commas, and punctuation
    text = re.sub(r'[^\w\s\',.!?]', ' ', text)

    # Remove multiple spaces
    text = re.sub(r'\s+', ' ', text).strip()
    text = re.sub(r'a href', ' ', text).strip()

    random_string_pattern = r'\b[A-Za-z0-9_]{15,}\b'  # Matches strings with 15 or more alphanumeric characters and underscores
    
    # Use regex to find all matches of random strings
    random_strings = re.findall(random_string_pattern, text)
    
    # Replace each random string with an empty string
    for random_string in random_strings:
        text = text.replace(random_string, '')

    

    return text


def process_text(text):
    text = clean_text(text)

    # Remove digits
    text = re.sub(r'\d+', '', text)
    text = re.sub(r'\bs.\b', '.', text)
    text = re.sub(r'\bs\b', '', text)

    # Lowercase the text
    text = text.lower()
    
    # Tokenize the text
    tokens = word_tokenize(text)
    
    # Lemmatize the tokens
    lemmatizer = WordNetLemmatizer()
    tagged_tokens = nltk.pos_tag(tokens)
    
    lemmatized_tokens = []
    for token, tag in tagged_tokens:
        # Lemmatize only nouns, verbs, adjectives, and adverbs
        if tag.startswith('N') or tag.startswith('V') or tag.startswith('J') or tag.startswith('R'):
            # Map NLTK's part-of-speech tags to WordNet's
            pos = get_wordnet_pos(tag)
            if pos:
                lemmatized_token = lemmatizer.lemmatize(token, pos=pos)
            else:
                # If no mapping available, lemmatize as a noun by default
                lemmatized_token = lemmatizer.lemmatize(token)
            lemmatized_tokens.append(lemmatized_token)
    
    # Remove stopwords, keeping negations and other sentiment-related words
    stop_words = set(stopwords.words("english"))
    words_to_remove = {"no", "not", "never"}
    stop_words -= words_to_remove
    lemmatized_tokens = [token for token in lemmatized_tokens if token not in stop_words]

    return " ".join(lemmatized_tokens)

tool = language_tool_python.LanguageTool('en-US')

# Function to correct text
def correct_text(text):
    matches = tool.check(text)
    return language_tool_python.utils.correct(text, matches)

df["CleanedText"] = df["text"].apply(clean_text)
df["ProcessText"] = df["text"].apply(process_text)
#df["CleanedText"] = df['CleanedText'].apply(correct_text)

df = df.dropna(subset=["CleanedText"])
    
df['ActualLabel'] = ""

df.to_csv("./CleanedCommentsV2/cleaned_youtube_comments20.csv", index=False, sep=';')