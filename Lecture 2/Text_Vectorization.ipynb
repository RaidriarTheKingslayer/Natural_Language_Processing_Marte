{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b736512-9858-4bda-97c9-c3abf00220bf",
   "metadata": {},
   "source": [
    "$\\textbf{Text Vectorization}$\n",
    "-\n",
    "\n",
    "- a vector is a geometric object which contains a magnitude and a direction.\n",
    "\n",
    "- Text vectorization is the projection of words into a mathematical space while preserving information.\n",
    "\n",
    "$\\textbf{The Bag of Words Model}$\n",
    "-\n",
    "\n",
    "- The BOW is a straight forward model for vectorizing sentences.\n",
    "\n",
    "- BOW uses word frequencies to construct vectors.\n",
    "\n",
    "- BOW model is an orderless document representation and only the counts of the words matter.\n",
    "\n",
    "- Because BOW does not take into account the positioning of words we loss smenatic information.\n",
    "\n",
    "- Vectorizing different sentences and joining the result into a single vocabulary.\n",
    "\n",
    "- The vocabulary acts as a reference if a specific word is present or absent in each of the sentence.\n",
    "\n",
    "$EXAMPLE$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "15453f40-a0f4-4f3a-8e9f-b1d74636fd84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['love', 'sat', 'dog', 'mat', 'cat']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "s1 = \"dog sat mat.\"\n",
    "s2 = \"cat love dog.\"\n",
    "\n",
    "def token_sentence(s):\n",
    "    # Make a regular expression that matches all punctuation\n",
    "    regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    # Use the regex\n",
    "    res = regex.sub('', s)\n",
    "    res = res.split()\n",
    "    return res\n",
    "\n",
    "new_s1 = token_sentence(s1)\n",
    "new_s2 = token_sentence(s2)\n",
    "vocabulary = list(set(new_s1 + new_s2))\n",
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "05ca5929-3e4f-4ce7-a40e-ed454af9812f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dog', 'sat', 'mat']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "87c86c6b-4122-4186-b631-998bd84d378f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 1, 0]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BOW = [int(u in new_s1) for u in vocabulary]\n",
    "BOW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07116216-ed5e-421d-95e7-fd69f1115685",
   "metadata": {},
   "source": [
    "$\\text{Term Frequency Inverse Document Frequency (TF-IDF)}$\n",
    "-\n",
    "\n",
    "- A model largely used in search engines to query relevant documents.\n",
    "\n",
    "- Two informations are encoded: the term frequency, and the inverse document frequency.\n",
    "\n",
    "- The term frequency is the count of words appearing in a document.\n",
    "\n",
    "- The inverse document frequency measures the importance of words in a document.\n",
    "\n",
    "- The inverse document frequency is calculated by logarithmically scaling the inverse fraction of the documents containing the word. This is obtained by dividing the total number of documents by the number of documents containing the term, followed by taking the logarithm of the ratio.\n",
    "\n",
    "- The inverse document frequency measures how common or rare a term is among all documents.\n",
    "\n",
    "The formula are:\n",
    "\\begin{gather}\n",
    "TF(t) = \\frac{\\text{number of times the term \"t\" appeas in a specific document}}{\\text{total number of terms in the document}}\n",
    "\\end{gather}\n",
    "\n",
    "\\begin{gather}\n",
    "IDF(t) = log(\\frac{\\text{total number of documents}}{\\text{number of documents with term \"t\"}})\n",
    "\\end{gather}\n",
    "\n",
    "\\begin{gather}\n",
    "TF \\cdotp IDF = TF(t) \\cdotp IDF(t)\n",
    "\\end{gather}\n",
    "\n",
    "- TF-IDF has more information that using vector representation because instead of using the count of words as used in the BOW, TF-IDF makes rare terms more prominent and ignores common words like stopwords such as \"is\", \"that\", \"of\", etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524507ac-0062-4b88-b0f3-e17f80564ee5",
   "metadata": {},
   "source": [
    "$\\text{Vectorization Using Gensim}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0e0be93f-0819-40a8-9604-4da4916737f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "documents = [\"Harmful algal blooms (HABs) occur when algae or cyanobacteria grow excessively, causing harm to humans, animals, or the environment.\"\n",
    "             ,\"Factors that contribute to HABs in salt, brackish, and freshwater bodies include nutrient pollution (e.g., nitrogen and phosphorus run off from land-based sources) and warmer water temperatures.\"\n",
    "             ,\"Climate change effects might alter the occurrence and severity of HABs in the U.S., increasing the risk to human health and well-being.\"\n",
    "             ,\"Health effects in humans are usually associated with exposures to toxins produced during a HAB.\"\n",
    "             ,\"Illnesses caused by HABs encompass a range of symptoms and severity, dependent on factors such as types and concentrations of algae, cyanobacteria, and toxins involved as well as exposure routes and pre-existing conditions (e.g., asthma).\"\n",
    "             ,\"To diagnose HAB-associated illnesses, providers need a basic awareness of HABs and the ability to identify clinical presentations and exposures.\",\"HAB-associated illnesses are primarily a diagnosis of exclusion because clinical testing options for HAB toxins are lacking; ideally, providers have access to clinical diagnostic testing to rule out other possible causes. \"\n",
    "             ,\"Healthcare providers contribute to public health efforts when they identify and report HAB-associated illnesses to their jurisdictional health authority.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1b506768-b958-45c7-b94a-e50ac8ea6571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['harmful', 'algal', 'bloom', 'hab', 'occur', 'algae', 'cyanobacteria', 'grow', 'excessively', 'cause', 'harm', 'human', 'animal', 'environment'], ['factor', 'contribute', 'hab', 'salt', 'brackish', 'freshwater', 'body', 'include', 'nutrient', 'pollution', 'e.g.', 'nitrogen', 'phosphoru', 'run', 'land', 'base', 'source', 'warm', 'water', 'temperature'], ['climate', 'change', 'effect', 'alter', 'occurrence', 'severity', 'hab', 'U.S.', 'increase', 'risk', 'human', 'health'], ['health', 'effect', 'human', 'usually', 'associate', 'exposure', 'toxin', 'produce', 'HAB'], ['illness', 'cause', 'hab', 'encompas', 'range', 'symptom', 'severity', 'dependent', 'factor', 'type', 'concentration', 'algae', 'cyanobacteria', 'toxin', 'involve', 'exposure', 'route', 'pre', 'existing', 'condition', 'e.g.', 'asthma'], ['diagnose', 'HAB', 'associate', 'illness', 'provider', 'need', 'basic', 'awareness', 'hab', 'ability', 'identify', 'clinical', 'presentation', 'exposure'], ['HAB', 'associate', 'illness', 'primarily', 'diagnosis', 'exclusion', 'clinical', 'testing', 'option', 'HAB', 'toxin', 'lack', 'ideally', 'provider', 'access', 'clinical', 'diagnostic', 'testing', 'rule', 'possible', 'cause'], ['healthcare', 'provider', 'contribute', 'public', 'health', 'effort', 'identify', 'report', 'HAB', 'associate', 'illness', 'jurisdictional', 'health', 'authority']]\n"
     ]
    }
   ],
   "source": [
    "texts = []\n",
    "for document in documents:\n",
    "    text = []\n",
    "    doc = nlp(document)\n",
    "    for w in doc:\n",
    "        if not w.is_stop and not w.is_punct and not w.like_num:\n",
    "            text.append(w.lemma_)\n",
    "    texts.append(text)\n",
    "#texts is a mini-corpus specifically for toxic algal bloom\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ce52e115-56cb-4821-9a51-2822e46126e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algae': 0, 'algal': 1, 'animal': 2, 'bloom': 3, 'cause': 4, 'cyanobacteria': 5, 'environment': 6, 'excessively': 7, 'grow': 8, 'hab': 9, 'harm': 10, 'harmful': 11, 'human': 12, 'occur': 13, 'base': 14, 'body': 15, 'brackish': 16, 'contribute': 17, 'e.g.': 18, 'factor': 19, 'freshwater': 20, 'include': 21, 'land': 22, 'nitrogen': 23, 'nutrient': 24, 'phosphoru': 25, 'pollution': 26, 'run': 27, 'salt': 28, 'source': 29, 'temperature': 30, 'warm': 31, 'water': 32, 'U.S.': 33, 'alter': 34, 'change': 35, 'climate': 36, 'effect': 37, 'health': 38, 'increase': 39, 'occurrence': 40, 'risk': 41, 'severity': 42, 'HAB': 43, 'associate': 44, 'exposure': 45, 'produce': 46, 'toxin': 47, 'usually': 48, 'asthma': 49, 'concentration': 50, 'condition': 51, 'dependent': 52, 'encompas': 53, 'existing': 54, 'illness': 55, 'involve': 56, 'pre': 57, 'range': 58, 'route': 59, 'symptom': 60, 'type': 61, 'ability': 62, 'awareness': 63, 'basic': 64, 'clinical': 65, 'diagnose': 66, 'identify': 67, 'need': 68, 'presentation': 69, 'provider': 70, 'access': 71, 'diagnosis': 72, 'diagnostic': 73, 'exclusion': 74, 'ideally': 75, 'lack': 76, 'option': 77, 'possible': 78, 'primarily': 79, 'rule': 80, 'testing': 81, 'authority': 82, 'effort': 83, 'healthcare': 84, 'jurisdictional': 85, 'public': 86, 'report': 87}\n"
     ]
    }
   ],
   "source": [
    "#creating a BOW representation of the mini-corpus\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301c05e0-56b6-4b11-b502-df817f675c57",
   "metadata": {},
   "source": [
    "$INSIGHTS$\n",
    "\n",
    "- There are 87 unique words in our corpus that is focused on healthcare and toxic algal bloom.\n",
    "\n",
    "- Each word is indexed with an integer.\n",
    "\n",
    "- The index is termed as a \"word ID\".\n",
    "\n",
    "- The BOW now can be used for word integer-id mapping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c5abbe-918d-45b7-8e38-8f0e00c2db1e",
   "metadata": {},
   "source": [
    "Using the doc2bow method, which, as the name suggests, helps convert our document to bag-of-words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "801b1848-d1c6-435e-8ee8-c7c50c572f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1),\n",
       "  (1, 1),\n",
       "  (2, 1),\n",
       "  (3, 1),\n",
       "  (4, 1),\n",
       "  (5, 1),\n",
       "  (6, 1),\n",
       "  (7, 1),\n",
       "  (8, 1),\n",
       "  (9, 1),\n",
       "  (10, 1),\n",
       "  (11, 1),\n",
       "  (12, 1),\n",
       "  (13, 1)],\n",
       " [(9, 1),\n",
       "  (14, 1),\n",
       "  (15, 1),\n",
       "  (16, 1),\n",
       "  (17, 1),\n",
       "  (18, 1),\n",
       "  (19, 1),\n",
       "  (20, 1),\n",
       "  (21, 1),\n",
       "  (22, 1),\n",
       "  (23, 1),\n",
       "  (24, 1),\n",
       "  (25, 1),\n",
       "  (26, 1),\n",
       "  (27, 1),\n",
       "  (28, 1),\n",
       "  (29, 1),\n",
       "  (30, 1),\n",
       "  (31, 1),\n",
       "  (32, 1)],\n",
       " [(9, 1),\n",
       "  (12, 1),\n",
       "  (33, 1),\n",
       "  (34, 1),\n",
       "  (35, 1),\n",
       "  (36, 1),\n",
       "  (37, 1),\n",
       "  (38, 1),\n",
       "  (39, 1),\n",
       "  (40, 1),\n",
       "  (41, 1),\n",
       "  (42, 1)],\n",
       " [(12, 1),\n",
       "  (37, 1),\n",
       "  (38, 1),\n",
       "  (43, 1),\n",
       "  (44, 1),\n",
       "  (45, 1),\n",
       "  (46, 1),\n",
       "  (47, 1),\n",
       "  (48, 1)],\n",
       " [(0, 1),\n",
       "  (4, 1),\n",
       "  (5, 1),\n",
       "  (9, 1),\n",
       "  (18, 1),\n",
       "  (19, 1),\n",
       "  (42, 1),\n",
       "  (45, 1),\n",
       "  (47, 1),\n",
       "  (49, 1),\n",
       "  (50, 1),\n",
       "  (51, 1),\n",
       "  (52, 1),\n",
       "  (53, 1),\n",
       "  (54, 1),\n",
       "  (55, 1),\n",
       "  (56, 1),\n",
       "  (57, 1),\n",
       "  (58, 1),\n",
       "  (59, 1),\n",
       "  (60, 1),\n",
       "  (61, 1)],\n",
       " [(9, 1),\n",
       "  (43, 1),\n",
       "  (44, 1),\n",
       "  (45, 1),\n",
       "  (55, 1),\n",
       "  (62, 1),\n",
       "  (63, 1),\n",
       "  (64, 1),\n",
       "  (65, 1),\n",
       "  (66, 1),\n",
       "  (67, 1),\n",
       "  (68, 1),\n",
       "  (69, 1),\n",
       "  (70, 1)],\n",
       " [(4, 1),\n",
       "  (43, 2),\n",
       "  (44, 1),\n",
       "  (47, 1),\n",
       "  (55, 1),\n",
       "  (65, 2),\n",
       "  (70, 1),\n",
       "  (71, 1),\n",
       "  (72, 1),\n",
       "  (73, 1),\n",
       "  (74, 1),\n",
       "  (75, 1),\n",
       "  (76, 1),\n",
       "  (77, 1),\n",
       "  (78, 1),\n",
       "  (79, 1),\n",
       "  (80, 1),\n",
       "  (81, 2)],\n",
       " [(17, 1),\n",
       "  (38, 2),\n",
       "  (43, 1),\n",
       "  (44, 1),\n",
       "  (55, 1),\n",
       "  (67, 1),\n",
       "  (70, 1),\n",
       "  (82, 1),\n",
       "  (83, 1),\n",
       "  (84, 1),\n",
       "  (85, 1),\n",
       "  (86, 1),\n",
       "  (87, 1)]]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872bb77c-6c24-4c81-87b6-267220cfabcb",
   "metadata": {},
   "source": [
    "- The output is a nested list.\n",
    "\n",
    "- Each individual sublist represents a documents bag-of-words representation.\n",
    "\n",
    "- A reminder: you might see different numbers in your list, this is because each time you create a dictionary, different mappings will occur.\n",
    "\n",
    "- Unlike the example we demonstrated, where an absence of a word was a 0, we use tuples that represent (word_id, word_count).\n",
    "\n",
    "- We can easily verify this by checking the original sentence, mapping each word to its integer ID and reconstructing our list.\n",
    "\n",
    "- We can also notice in this case each document has not greater than one count of each word - in smaller corpuses, this tends to happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fd28cb55-4fb5-46fe-8405-dc84d12c7a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing your generated corpus\n",
    "\n",
    "corpora.MmCorpus.serialize('/tmp/example.mm', corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56ae242-51ef-4169-8f5b-f1609372b15b",
   "metadata": {},
   "source": [
    "- It is more memory efficient to store your corpus into the disk and later loading it because at most one vector resides in the RAM at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0b091d55-bb06-406c-8832-031cbec45f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.20687441490900804), (1, 0.31031162236351206), (2, 0.31031162236351206), (3, 0.31031162236351206), (4, 0.14636752736880834), (5, 0.20687441490900804), (6, 0.31031162236351206), (7, 0.31031162236351206), (8, 0.31031162236351206), (9, 0.07013786431820669), (10, 0.31031162236351206), (11, 0.31031162236351206), (12, 0.14636752736880834), (13, 0.31031162236351206)]\n",
      "[(9, 0.05420937381791797), (14, 0.2398390498522999), (15, 0.2398390498522999), (16, 0.2398390498522999), (17, 0.15989269990153326), (18, 0.15989269990153326), (19, 0.15989269990153326), (20, 0.2398390498522999), (21, 0.2398390498522999), (22, 0.2398390498522999), (23, 0.2398390498522999), (24, 0.2398390498522999), (25, 0.2398390498522999), (26, 0.2398390498522999), (27, 0.2398390498522999), (28, 0.2398390498522999), (29, 0.2398390498522999), (30, 0.2398390498522999), (31, 0.2398390498522999), (32, 0.2398390498522999)]\n",
      "[(9, 0.07805568921230585), (12, 0.1628908769625549), (33, 0.34534253059492104), (34, 0.34534253059492104), (35, 0.34534253059492104), (36, 0.34534253059492104), (37, 0.23022835372994738), (38, 0.1628908769625549), (39, 0.34534253059492104), (40, 0.34534253059492104), (41, 0.34534253059492104), (42, 0.23022835372994738)]\n",
      "[(12, 0.2501092157670636), (37, 0.3535018907902139), (38, 0.2501092157670636), (43, 0.17675094539510694), (44, 0.17675094539510694), (45, 0.2501092157670636), (46, 0.5302528361853208), (47, 0.2501092157670636), (48, 0.5302528361853208)]\n",
      "[(0, 0.17183578052203283), (4, 0.12157703657826278), (5, 0.17183578052203283), (9, 0.058258507532545946), (18, 0.17183578052203283), (19, 0.17183578052203283), (42, 0.17183578052203283), (45, 0.12157703657826278), (47, 0.12157703657826278), (49, 0.2577536707830492), (50, 0.2577536707830492), (51, 0.2577536707830492), (52, 0.2577536707830492), (53, 0.2577536707830492), (54, 0.2577536707830492), (55, 0.08591789026101641), (56, 0.2577536707830492), (57, 0.2577536707830492), (58, 0.2577536707830492), (59, 0.2577536707830492), (60, 0.2577536707830492), (61, 0.2577536707830492)]\n",
      "[(9, 0.08135691446371011), (43, 0.11998272432507807), (44, 0.11998272432507807), (45, 0.16978005418562137), (55, 0.11998272432507807), (62, 0.3599481729752342), (63, 0.3599481729752342), (64, 0.3599481729752342), (65, 0.23996544865015615), (66, 0.3599481729752342), (67, 0.23996544865015615), (68, 0.3599481729752342), (69, 0.3599481729752342), (70, 0.16978005418562137)]\n",
      "[(4, 0.11402438220709378), (43, 0.16116093356565447), (44, 0.08058046678282724), (47, 0.11402438220709378), (55, 0.08058046678282724), (65, 0.32232186713130895), (70, 0.11402438220709378), (71, 0.24174140034848168), (72, 0.24174140034848168), (73, 0.24174140034848168), (74, 0.24174140034848168), (75, 0.24174140034848168), (76, 0.24174140034848168), (77, 0.24174140034848168), (78, 0.24174140034848168), (79, 0.24174140034848168), (80, 0.24174140034848168), (81, 0.48348280069696337)]\n",
      "[(17, 0.23092216476345012), (38, 0.3267635225549296), (43, 0.11546108238172506), (44, 0.11546108238172506), (55, 0.11546108238172506), (67, 0.23092216476345012), (70, 0.1633817612774648), (82, 0.34638324714517515), (83, 0.34638324714517515), (84, 0.34638324714517515), (85, 0.34638324714517515), (86, 0.34638324714517515), (87, 0.34638324714517515)]\n"
     ]
    }
   ],
   "source": [
    "#Converting Bag-of-Words to TF-IDF representation\n",
    "from gensim import models\n",
    "tfidf = models.TfidfModel(corpus)\n",
    "\n",
    "for document in tfidf[corpus]:\n",
    "       print(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b163e098-a7bb-4b74-9feb-d699bc2de793",
   "metadata": {},
   "source": [
    "- TF-IDF scores: The higher the score, the more important the word in the document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c612c4-f77c-4992-acb1-54bf9a20b26a",
   "metadata": {},
   "source": [
    "$\\textbf{N-Gramming}$\n",
    "-\n",
    "\n",
    "- Context is very important when working with text data.\n",
    "- This context is lost during vector representation because on only the word frequency is taken into account.\n",
    "- An n-gram is a contiguous sequence of n items in the text. In our case, we will be dealing with words being the item, but depending on the use case, it could be even letters, syllables, or sometimes in the case of speech, phonemes.\n",
    "- Mono-gram, n=1\n",
    "- Bi-gram, n = 2.\n",
    "- Tri-gram, n=3\n",
    "- N-Gramming is calculated through the conditional probability of a token given by thr preceding token.\n",
    "- N-Gramming can also be done by calculating words that appear close to each other.\n",
    "- Bi-gramming is also called co-location, it locates pair of words that are very likely to appear close together.\n",
    "- Example: \"New Hampshire\" is one word not \"New\" and \"Hampshire\"\n",
    "- Gensim approaches bigrams by simply combining the two high probability tokens with an underscore. The tokens new and york will now become new_york instead. Similar to the TF- IDF model, bigrams can be created using another Gensim model - Phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a3eb89c2-8315-4b7e-82c9-a2b09daa78ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['harmful',\n",
       "  'algal',\n",
       "  'bloom',\n",
       "  'hab',\n",
       "  'occur',\n",
       "  'algae',\n",
       "  'cyanobacteria',\n",
       "  'grow',\n",
       "  'excessively',\n",
       "  'cause',\n",
       "  'harm',\n",
       "  'human',\n",
       "  'animal',\n",
       "  'environment'],\n",
       " ['factor',\n",
       "  'contribute',\n",
       "  'hab',\n",
       "  'salt',\n",
       "  'brackish',\n",
       "  'freshwater',\n",
       "  'body',\n",
       "  'include',\n",
       "  'nutrient',\n",
       "  'pollution',\n",
       "  'e.g.',\n",
       "  'nitrogen',\n",
       "  'phosphoru',\n",
       "  'run',\n",
       "  'land',\n",
       "  'base',\n",
       "  'source',\n",
       "  'warm',\n",
       "  'water',\n",
       "  'temperature'],\n",
       " ['climate',\n",
       "  'change',\n",
       "  'effect',\n",
       "  'alter',\n",
       "  'occurrence',\n",
       "  'severity',\n",
       "  'hab',\n",
       "  'U.S.',\n",
       "  'increase',\n",
       "  'risk',\n",
       "  'human',\n",
       "  'health'],\n",
       " ['health',\n",
       "  'effect',\n",
       "  'human',\n",
       "  'usually',\n",
       "  'associate',\n",
       "  'exposure',\n",
       "  'toxin',\n",
       "  'produce',\n",
       "  'HAB'],\n",
       " ['illness',\n",
       "  'cause',\n",
       "  'hab',\n",
       "  'encompas',\n",
       "  'range',\n",
       "  'symptom',\n",
       "  'severity',\n",
       "  'dependent',\n",
       "  'factor',\n",
       "  'type',\n",
       "  'concentration',\n",
       "  'algae',\n",
       "  'cyanobacteria',\n",
       "  'toxin',\n",
       "  'involve',\n",
       "  'exposure',\n",
       "  'route',\n",
       "  'pre',\n",
       "  'existing',\n",
       "  'condition',\n",
       "  'e.g.',\n",
       "  'asthma'],\n",
       " ['diagnose',\n",
       "  'HAB',\n",
       "  'associate',\n",
       "  'illness',\n",
       "  'provider',\n",
       "  'need',\n",
       "  'basic',\n",
       "  'awareness',\n",
       "  'hab',\n",
       "  'ability',\n",
       "  'identify',\n",
       "  'clinical',\n",
       "  'presentation',\n",
       "  'exposure'],\n",
       " ['HAB',\n",
       "  'associate',\n",
       "  'illness',\n",
       "  'primarily',\n",
       "  'diagnosis',\n",
       "  'exclusion',\n",
       "  'clinical',\n",
       "  'testing',\n",
       "  'option',\n",
       "  'HAB',\n",
       "  'toxin',\n",
       "  'lack',\n",
       "  'ideally',\n",
       "  'provider',\n",
       "  'access',\n",
       "  'clinical',\n",
       "  'diagnostic',\n",
       "  'testing',\n",
       "  'rule',\n",
       "  'possible',\n",
       "  'cause'],\n",
       " ['healthcare',\n",
       "  'provider',\n",
       "  'contribute',\n",
       "  'public',\n",
       "  'health',\n",
       "  'effort',\n",
       "  'identify',\n",
       "  'report',\n",
       "  'HAB',\n",
       "  'associate',\n",
       "  'illness',\n",
       "  'jurisdictional',\n",
       "  'health',\n",
       "  'authority']]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "bigram = gensim.models.Phrases(texts)\n",
    "texts = [bigram[line] for line in texts]\n",
    "texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c48145-2d7d-4bef-9c83-622cce63c0ab",
   "metadata": {},
   "source": [
    "$\\textbf{NOTE}:$Since by creating new phrases we add words to our dictionary, this step must be done before we create our dictionary. We would have to run this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "afbd5839-6714-4498-a6f3-c2086ba06d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06f30b2-849e-4c3f-92ab-959c9048d8b3",
   "metadata": {},
   "source": [
    "After we are done creating our bi-grams, we can create tri-grams, and other n-grams by simply running the phrases model multiple times on our corpus. Bi-grams still remains the most used n-gram model, though it is worth one's time to glance over the other uses and kinds of n-gram implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d3c80adf-ac0e-40a7-985d-168183113ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing both high frequency and low-frequency words.\n",
    "# Example: get rid of words that occur in less than 20 documents, or in more than 50% of the documents, \n",
    "dictionary.filter_extremes(no_below=20, no_above=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8048d733-c179-4a97-b02a-e7572cf7c80b",
   "metadata": {},
   "source": [
    "$\\textbf{Programming Assignment}$\n",
    "\n",
    "Choose a topic that you will be using as a term paper for this subject. Collect articles, publications, sotries etc. of your chosen topic and develop your own mini-corpus using the preprocessing steps required. Be sure to print the output.\n",
    "\n",
    "Note that this corpus will be used for the entire subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f91a849-ac61-4038-b37e-db8b9cbcd6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "df = pd.read_csv(\"../cleaned_youtube_comments.csv\", sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bd9d4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6d3c2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6475ea37",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = df.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "687a7c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    It's comforting to know that even A.I. struggl...\n",
       "1    What's insane is that the A.I is still in its ...\n",
       "2    As a doctor, I can see the limitations now, bu...\n",
       "3    The fact that AI is so recent and is able to n...\n",
       "4    Whats insane is that people keep using AI, the...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18d1ffcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['comfort', 'know', 'A.I.', 'struggle', 'find', 'right', 'career', 'path'], ['insane', 'A.I', 'Infancy', 'stage', 'able', 'like', 'right', 'profession'], ['doctor', 'limitation', 'improve', 'super', 'fast', 'especially', 'radiology'], ['fact', 'AI', 'recent', 'able', 'nearly', 'job', 'show', 'potential'], ['s', 'insane', 'people', 'AI', 'lead', 'AI', 'nuanced', 'compatible', 'job', 'stop', 'AI', 'worry', 'computer', 'take', 'job'], ['video', 'month', 'old', 'difference', 'result', 'run', 'test', 'substantial', 'time', 'group', 'test', 'AI', 'confident'], ['AI', 'job', 'people', 'AI'], ['video', 'bring', 'mind', 'progression', 'AI', 'game', 'like', 'chess', 'StarCraft', 'people', 'believe', 'AI', 'beat', 'chess', 'champion', 'soon', 'AI', 'defeat', 'world', 'chess', 'champion', 'critic', 'argue', 'chess', 'simple', 'AI', 'try', 'AlphaGo', 'prove', 'wrong', 'defeat', 'Lee', 'Sedol', 'player', 'subsequently', 'skeptic', 'claim', 'AI', 'able', 'excel', 'strategy', 'game', 'like', 'StarCraft', 'II', 'AI', 'triumph', 'Serral', 'professional', 'player', 'people', 'fail', 'understand', 'AI', 'model', 'case', 'ChatGPT3.5', 'begin', ' ', 'future', 'iteration', 'model', 'advanced', 'impressive', 'Elon', 'Musk', 'urge', 'AI', 'pause'], ['love', 'interview', 'year', 'people'], ['frustrating', 'actual', 'prompt', 'criticism', 'AI', 'result', 'directly', 'result'], ['confidently', 'stare', 'camera', 'say', 'AI', 'not', 'job', 'm', 'guess', 'video', 'go', 'to', 'age'], ['proper', 'prompt', 'engineering', 'guidance', 'multiple', 'prompt', 'video', 'completely', 'different', 'people', 'feel', 'threatened'], ['litterally', 'everybody', 'influencer', 'especcially', 'god', 'ai'], ['AI', 'replace', 'person', 'AI', 'replace'], ['thing', 'lot', 'people', 'like', 'trainer', 'enter', 'info', 'client', 'ai', 'respond', 'accordingly', 'ask', 'question'], ['chatgpt', 'probably', 'specific', 'lawyer', 'example', 'state', 'mention', 'section', 'penalty', 'forth'], ['lol', 'influencer', 'job', 'lololol'], ['translator', 'machine', 'translation', 'useful', 'helpful', 'tool', 'job', 'efficient', 'amazed', 'bit', 'scared', 'translate', 'natural', 'sound', 'help', 'translation', 'memory', 'tend', 'major', 'critical', 'error', 'instead', 'especially', 'product', 'name', 'culturerelate', 'material', 'lay', 'bit', 'lol', 'scare', 'overwhelm'], ['href', 'thing', 'fat', 'burn', 'workout', 'fat', 'loss', 'entirely', 'achieve', 'caloric', 'deficit'], ['lie'], ['funny', 'job', 'ai', 'not', 'moment', 'minimum', 'wage', 'make', 'think'], ['bchatgpt', 'improvingb', 'Software', 'engineer', 'graphic', 'designer', 'Screenwriter', 'Journalist', 'Copywriter', 'replace', 'year'], ['wish', 'say', 'ai', 'fail', 'actually', 'follow', 'question', 'watch', 'scary', 'accurate', 'take', 'multiple', 'prompt'], ['go', 'fun', 'watch', 'like', 'year', 'video', 'randomly', 'recommend', 'people', 'feed', 'like', '90', 'computer', ' ', 'internet', 'commercial', 'ramdomly', 'pop', 'feed'], ['find', 'insufferable', 'touch', 'people', 'find'], ['copywriter', 'defensive', 'know', 'influencer', 'dumb', 'hear', 'argument', 'hope', 'replace'], ['people', 'not', 'lack', 'knowledge', 'lack', 'ability', 'follow'], ['circus', 'artist', 'future'], ['people', 'understand', 'come', 'year', 'ago', 'imagine', '5yrs', 'road', 'job', 'finish', 'GPT3', 'GPT4', 'massive', 'difference', 'GPT4', 'pass', 'bar'], ['fire', 'Firghter', 'way', 'A.I', 'jobQuick', 'google', 'find', 'A.I', 'drive', 'robot', 'help', 'firefighter', ' ', 'writing', 'wall'], ['arrange', 'firefighter', 'end', 'probably', 'humor', 'actually', 'remind', 'grateful', 'have', 'people', 'willing', 'dangerous', 'job', 'protect', 'neighborhood'], ['therapist', 'influencer', 'job', 'earn'], ['radiologist', 'deny', 'job', 'will', 'replace', 'ai', 'funny', 'consider', 'fast', 'ai', 'develop', 'field'], ['Firefighter', 'well', 'watch'], ['know', 'realize', 'important', 'point', 'AI', 'able', 'permorfm', 'professional', 'level', 'job', 'able', 'close', 'conclude', 'AI', 'kinda', 'know', 'job', 'way', 'people', 'kinda', 'job', 'time', 'scary', 'right', 'AI', 'start', 'grow', 'let', 'wait', 'couple', 'year', 'happen'], ['href', 'prove', 'certain', 'kweb', 'feller'], ['problem', 'highly', 'specialized', 'evolve', 'ai', 'start', 'year', 'ai', 'job', 'time', 'well'], ['7month', 'future', 'bet', 'people', 'freak', 'right'], ['like', 'circus', 'artist', 'fire', 'fighter'], ['ai', 'defense', 'misleading', 'train', 'model', 'ask', 'correction', 'regenerate', 'response', 'etc', 'professional', 'answer', 'complicated', 'question', 'perfectly', 'try', 'hold', 'AI', 'standard'], ['AI', 'go', 'to', 'kill', 'para', 'legal'], ['lol', 'graphic', 'designer'], ['soon', 'replace', 'AI', 'movie', 'broadcaster', 'AI', 'jobsi', 'suggest', 'want', 'replace', 'refuse', 'watch', 'AI', 'movie', 'AI', 'television', 'show', 'use', 'product', 'support', 'business', 'not', 'support'], ['a.i', 'barely', 'program'], ['sorry', 'AI', 'definitely', 'replace', 'journalist', 'fitness', 'coach'], ['reassure', 'lot', 'thing', 'thank', 'wellmade', 'research', 'video', 'sad', 'artist'], ['wait', 'year'], ['bro', 'wtf', 'comment', 'haha', 'denial', 'haha', 'ai', 'replace', 'job', 'like', 'laugh', 'defend', 'job', 'lmfao', 'cry', 'AI', 'cause', 'massive', 'layoff', 'day', 'haha', 'people'], ['feline', 'phobic', 'dislike', 'cat', 'offensive', 'getting', 'cancel'], ['haven', 'give', 'AI', 'well', 'prompt', 'well', 'output', 'people', 'simple', 'want', 'accept', 'reality'], ['AI', 'will', 'job', 'effectively', 'utilize', 'AI'], ['imagine', 'ask', 'month', 'improve'], ['issue', 'video', 'prompt', 'write', 'experienced', 'writing', 'prompt', 'specific', 'AI', 'know', 'strength', 'weakness', 'write', 'prompt', 'likely', 'well', 'result', 'example', 'translator', 'specify', 'tone', 'want', 'translation', 'like', 'formal', 'likely', 'consistent', 'result'], ['ironically', 'blue', 'colar', 'job', 'like', 'firefighter', 'chef', 'replace', 'ai'], ['year', 'video', 'age'], ['age', 'terribly', 'get', 'like', 'company', 'announce', 'come', 'general', 'purpose', 'robot', '70k', 'new', 'layoff', 'AI', 'replacement', 'week'], ['age', 'pretty', 'bad'], ['href', 'india', 'grandfather', 'say', 'new', 'channel', 'hire', 'foreigner', 'talk', 'Hindi', 'see', 'ai', 'female', 'new', 'reporter'], ['man', 'news', 'anchor', 'denial', 'look', 'robot', 'lol'], ['therapist', 'cope'], ['curse'], ['despite', 'denial', 'new', 'unemployed', 'guy'], ['physical', 'job', ' ', 'replace', 'ai', 'robot', 'create', 'heavy', 'work'], ['comment', 'section', 'weird', 'like', 'commenter', 'expect', 'people', 'happy', 'replace', 'near', 'future'], ['EGO', 'strong'], ['age'], ['type', 'prompt', 'follow', 'prompt', 'individual', 'scared', 'conjure', 'test', 'real', 'understanding', 'AI', 'work'], ['maybe', 'video', 'maybe', 'genuine', 'hopeful', 'view', 'think', 'people', 'realise', 'quickly', 'actually', 'go', 'replace'], ['thing', 'get', 'nerve', 'video', 'usually', 'want', 'information', 'not', 'ask', 'ai', 'information', 'chatgpt', 'elaborate', 'information', 'provide', 'ask'], ['people', 'denial', 'software', 'engineer', 'happy', 'xd', 'Edit', 'Forgot', 'firefighter', 'right'], ['funny', 'confident', 'proud', 'people', 'feeling', 'redundant'], ['A.I.', 'try', 'job', 'act', 'like', 'influencer'], ['WAY', 'AI', 'MAH', 'JOBme', 'job'], ['comedian', 'Influencers', 'dj', 'completely', 'useless', 'right'], ['People', 'work', 'tech', 'field', 'simply', 'amazed', 'feel', 'threaten', 'a.', 'i.'], ['like', 'give', 'AI', 'question', 'ask', 'perfect', 'answer', 'additional', 'followup', 'clarification', 'AI', 'function', 'properly', 'need', 'ask', 'additional', 'question', 'context', 'ask', 'elaborate', 'like', 'person', 'job'], ['shockingly', 'shortsighted', 'like', 'group', 'adult', 'discuss', 'dumb', 'toddler', 'AI', 'barely', 'nappy', 'point', 'person', 'declare', 'AI', 'not', 'job', 'add', ' ', 'end', 's', 'crucial', 'detail', 's', 'miss', 'lets', 'revisit', 'video', 'assess', 'impact'], ['firefighter', 'meme', 'day', 'A.I.', 'able'], ['guy', 'underestimate', 'boston', 'dynamic', 'robot'], ['job', 'need', 'physical', 'involvement', 'like', 'DJ', 'physical', 'trainer', 'obviously', 'computer', 'program', 'think', 'd', 'interesting', 'job', 'require', 'logical', 'thinking', 'knowledge', 'base', 'office', 'job', 'line', 'example', 'consultant', 'product', 'manager', 'engineer', 'banker', 'marketing', 'manager'], ['Lmaoo'], ['expectthat', 'person', 'say', 'yeah', 'AI', 'job', 'bye'], ['ego', 'unable', 'accept'], ['href', 'huh', 'wonder'], ['A.I.', 'like', 'teach', 'child', 'time', 'child', 'get', 'smart', 'know', 'student', 'surpass', 'teacher'], ['comedian', 'think', 'u', 'funny', 'job'], ['chat', 'gpt', 'sorta', 'job', 'specialize', 'ai', 'eventually'], ['gt', 'influencergt', 'call', 'job'], ['people', 'delusional', 'think', 'AI', 'not', 'replace', 'go', 'to', 'improve', 'time'], ['problem', 'face', 'ChatGPT', 'ask', 'question', 'like', 'prompt', 'say', 'beginning', 'state', 'job', 'blank', 'ExampleYou', 'couple', 'therapist', 'year', 'come', 'sort', 'problem', 'relationship', 'know', 'fix', 'listen', 'problem', 'reply', 'say', 'problem', 'good', 'capability', 'go', 'strong', 'information', 'feeling', 'counter', 'act', 'ask', 'question', 'refined', 'answer', 'send', 'hope', 'outdo', 'job'], ['actually', 'impressed', 'denial'], ['know', 'Graphic', 'Designer', 'job', 'AI', 'go', 'to', 'steal'], ['lawyer', 'not', 'specific', 'search', 'Ai', 've', 'give', 'well', 'answer', 'probably', 'well', 'year', 'lawyer', 'little', 'informed', 'year'], ['final', 'comment', 'people', 'que', 'ask', 'question', ' ', 'AI', 'give', 'response', 'ai', 'furhter', 'questiond', 'example', 'lawyer', 'Black', 'Law', 'Dictionary', 'thloowe', 'give', 'citation', ' ', 'Drs', 'ai', 'assist', 'early', 'cancer', 'detection', 'thing', 'doctor', 'ask', 'AI', 'referencee', 'DSM', 'therapist'], ['AI', 'job', 'correct', 'answer'], ['get', 'good', 'es', 'hear', 'People', 'lack', 'knowledge', 'lack', 'ability', 'follow'], ['lambaste', 'AI', 'ask', 'dogive', 'good', 'caption', 'photobgive', 'fantastic', 'captionbthis', 'sound', 'like', 'meyou', \"didn't\", 'tell', 'SOUND', 'like'], ['brutal', 'try', 'copywriter', 'prompt', 'GPT4', 'come', 'great', 'idea'], ['Lmao', 'circus', 'artist', 'like', 'tf'], ['matter', 'time']]\n"
     ]
    }
   ],
   "source": [
    "texts = []\n",
    "for document in documents:\n",
    "    text = []\n",
    "    doc = nlp(document)\n",
    "    for w in doc:\n",
    "        if not w.is_stop and not w.is_punct and not w.like_num:\n",
    "            text.append(w.lemma_)\n",
    "    texts.append(text)\n",
    "#texts is a mini-corpus specifically for toxic algal bloom\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e64d2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9ec605f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A.I.': 0, 'career': 1, 'comfort': 2, 'find': 3, 'know': 4, 'path': 5, 'right': 6, 'struggle': 7, 'A.I': 8, 'Infancy': 9, 'able': 10, 'insane': 11, 'like': 12, 'profession': 13, 'stage': 14, 'doctor': 15, 'especially': 16, 'fast': 17, 'improve': 18, 'limitation': 19, 'radiology': 20, 'super': 21, 'AI': 22, 'fact': 23, 'job': 24, 'nearly': 25, 'potential': 26, 'recent': 27, 'show': 28, 'compatible': 29, 'computer': 30, 'lead': 31, 'nuanced': 32, 'people': 33, 's': 34, 'stop': 35, 'take': 36, 'worry': 37, 'confident': 38, 'difference': 39, 'group': 40, 'month': 41, 'old': 42, 'result': 43, 'run': 44, 'substantial': 45, 'test': 46, 'time': 47, 'video': 48, ' ': 49, 'AlphaGo': 50, 'ChatGPT3.5': 51, 'Elon': 52, 'II': 53, 'Lee': 54, 'Musk': 55, 'Sedol': 56, 'Serral': 57, 'StarCraft': 58, 'advanced': 59, 'argue': 60, 'beat': 61, 'begin': 62, 'believe': 63, 'bring': 64, 'case': 65, 'champion': 66, 'chess': 67, 'claim': 68, 'critic': 69, 'defeat': 70, 'excel': 71, 'fail': 72, 'future': 73, 'game': 74, 'impressive': 75, 'iteration': 76, 'mind': 77, 'model': 78, 'pause': 79, 'player': 80, 'professional': 81, 'progression': 82, 'prove': 83, 'simple': 84, 'skeptic': 85, 'soon': 86, 'strategy': 87, 'subsequently': 88, 'triumph': 89, 'try': 90, 'understand': 91, 'urge': 92, 'world': 93, 'wrong': 94, 'interview': 95, 'love': 96, 'year': 97, 'actual': 98, 'criticism': 99, 'directly': 100, 'frustrating': 101, 'prompt': 102, 'age': 103, 'camera': 104, 'confidently': 105, 'go': 106, 'guess': 107, 'm': 108, 'not': 109, 'say': 110, 'stare': 111, 'to': 112, 'completely': 113, 'different': 114, 'engineering': 115, 'feel': 116, 'guidance': 117, 'multiple': 118, 'proper': 119, 'threatened': 120, 'ai': 121, 'especcially': 122, 'everybody': 123, 'god': 124, 'influencer': 125, 'litterally': 126, 'person': 127, 'replace': 128, 'accordingly': 129, 'ask': 130, 'client': 131, 'enter': 132, 'info': 133, 'lot': 134, 'question': 135, 'respond': 136, 'thing': 137, 'trainer': 138, 'chatgpt': 139, 'example': 140, 'forth': 141, 'lawyer': 142, 'mention': 143, 'penalty': 144, 'probably': 145, 'section': 146, 'specific': 147, 'state': 148, 'lol': 149, 'lololol': 150, 'amazed': 151, 'bit': 152, 'critical': 153, 'culturerelate': 154, 'efficient': 155, 'error': 156, 'help': 157, 'helpful': 158, 'instead': 159, 'lay': 160, 'machine': 161, 'major': 162, 'material': 163, 'memory': 164, 'name': 165, 'natural': 166, 'overwhelm': 167, 'product': 168, 'scare': 169, 'scared': 170, 'sound': 171, 'tend': 172, 'tool': 173, 'translate': 174, 'translation': 175, 'translator': 176, 'useful': 177, 'achieve': 178, 'burn': 179, 'caloric': 180, 'deficit': 181, 'entirely': 182, 'fat': 183, 'href': 184, 'loss': 185, 'workout': 186, 'lie': 187, 'funny': 188, 'make': 189, 'minimum': 190, 'moment': 191, 'think': 192, 'wage': 193, 'Copywriter': 194, 'Journalist': 195, 'Screenwriter': 196, 'Software': 197, 'bchatgpt': 198, 'designer': 199, 'engineer': 200, 'graphic': 201, 'improvingb': 202, 'accurate': 203, 'actually': 204, 'follow': 205, 'scary': 206, 'watch': 207, 'wish': 208, '90': 209, 'commercial': 210, 'feed': 211, 'fun': 212, 'internet': 213, 'pop': 214, 'ramdomly': 215, 'randomly': 216, 'recommend': 217, 'insufferable': 218, 'touch': 219, 'argument': 220, 'copywriter': 221, 'defensive': 222, 'dumb': 223, 'hear': 224, 'hope': 225, 'ability': 226, 'knowledge': 227, 'lack': 228, 'artist': 229, 'circus': 230, '5yrs': 231, 'GPT3': 232, 'GPT4': 233, 'ago': 234, 'bar': 235, 'come': 236, 'finish': 237, 'imagine': 238, 'massive': 239, 'pass': 240, 'road': 241, 'Firghter': 242, 'drive': 243, 'fire': 244, 'firefighter': 245, 'google': 246, 'jobQuick': 247, 'robot': 248, 'wall': 249, 'way': 250, 'writing': 251, 'arrange': 252, 'dangerous': 253, 'end': 254, 'grateful': 255, 'have': 256, 'humor': 257, 'neighborhood': 258, 'protect': 259, 'remind': 260, 'willing': 261, 'earn': 262, 'therapist': 263, 'consider': 264, 'deny': 265, 'develop': 266, 'field': 267, 'radiologist': 268, 'will': 269, 'Firefighter': 270, 'well': 271, 'close': 272, 'conclude': 273, 'couple': 274, 'grow': 275, 'happen': 276, 'important': 277, 'kinda': 278, 'let': 279, 'level': 280, 'permorfm': 281, 'point': 282, 'realize': 283, 'start': 284, 'wait': 285, 'certain': 286, 'feller': 287, 'kweb': 288, 'evolve': 289, 'highly': 290, 'problem': 291, 'specialized': 292, '7month': 293, 'bet': 294, 'freak': 295, 'fighter': 296, 'answer': 297, 'complicated': 298, 'correction': 299, 'defense': 300, 'etc': 301, 'hold': 302, 'misleading': 303, 'perfectly': 304, 'regenerate': 305, 'response': 306, 'standard': 307, 'train': 308, 'kill': 309, 'legal': 310, 'para': 311, 'broadcaster': 312, 'business': 313, 'jobsi': 314, 'movie': 315, 'refuse': 316, 'suggest': 317, 'support': 318, 'television': 319, 'use': 320, 'want': 321, 'a.i': 322, 'barely': 323, 'program': 324, 'coach': 325, 'definitely': 326, 'fitness': 327, 'journalist': 328, 'sorry': 329, 'reassure': 330, 'research': 331, 'sad': 332, 'thank': 333, 'wellmade': 334, 'bro': 335, 'cause': 336, 'comment': 337, 'cry': 338, 'day': 339, 'defend': 340, 'denial': 341, 'haha': 342, 'laugh': 343, 'layoff': 344, 'lmfao': 345, 'wtf': 346, 'cancel': 347, 'cat': 348, 'dislike': 349, 'feline': 350, 'getting': 351, 'offensive': 352, 'phobic': 353, 'accept': 354, 'give': 355, 'haven': 356, 'output': 357, 'reality': 358, 'effectively': 359, 'utilize': 360, 'consistent': 361, 'experienced': 362, 'formal': 363, 'issue': 364, 'likely': 365, 'specify': 366, 'strength': 367, 'tone': 368, 'weakness': 369, 'write': 370, 'blue': 371, 'chef': 372, 'colar': 373, 'ironically': 374, '70k': 375, 'announce': 376, 'company': 377, 'general': 378, 'get': 379, 'new': 380, 'purpose': 381, 'replacement': 382, 'terribly': 383, 'week': 384, 'bad': 385, 'pretty': 386, 'Hindi': 387, 'channel': 388, 'female': 389, 'foreigner': 390, 'grandfather': 391, 'hire': 392, 'india': 393, 'reporter': 394, 'see': 395, 'talk': 396, 'anchor': 397, 'look': 398, 'man': 399, 'news': 400, 'cope': 401, 'curse': 402, 'despite': 403, 'guy': 404, 'unemployed': 405, 'create': 406, 'heavy': 407, 'physical': 408, 'work': 409, 'commenter': 410, 'expect': 411, 'happy': 412, 'near': 413, 'weird': 414, 'EGO': 415, 'strong': 416, 'conjure': 417, 'individual': 418, 'real': 419, 'type': 420, 'understanding': 421, 'genuine': 422, 'hopeful': 423, 'maybe': 424, 'quickly': 425, 'realise': 426, 'view': 427, 'elaborate': 428, 'information': 429, 'nerve': 430, 'provide': 431, 'usually': 432, 'Edit': 433, 'Forgot': 434, 'software': 435, 'xd': 436, 'feeling': 437, 'proud': 438, 'redundant': 439, 'act': 440, 'JOBme': 441, 'MAH': 442, 'WAY': 443, 'Influencers': 444, 'comedian': 445, 'dj': 446, 'useless': 447, 'People': 448, 'a.': 449, 'i.': 450, 'simply': 451, 'tech': 452, 'threaten': 453, 'additional': 454, 'clarification': 455, 'context': 456, 'followup': 457, 'function': 458, 'need': 459, 'perfect': 460, 'properly': 461, 'add': 462, 'adult': 463, 'assess': 464, 'crucial': 465, 'declare': 466, 'detail': 467, 'discuss': 468, 'impact': 469, 'lets': 470, 'miss': 471, 'nappy': 472, 'revisit': 473, 'shockingly': 474, 'shortsighted': 475, 'toddler': 476, 'meme': 477, 'boston': 478, 'dynamic': 479, 'underestimate': 480, 'DJ': 481, 'banker': 482, 'base': 483, 'consultant': 484, 'd': 485, 'interesting': 486, 'involvement': 487, 'line': 488, 'logical': 489, 'manager': 490, 'marketing': 491, 'obviously': 492, 'office': 493, 'require': 494, 'thinking': 495, 'Lmaoo': 496, 'bye': 497, 'expectthat': 498, 'yeah': 499, 'ego': 500, 'unable': 501, 'huh': 502, 'wonder': 503, 'child': 504, 'smart': 505, 'student': 506, 'surpass': 507, 'teach': 508, 'teacher': 509, 'u': 510, 'chat': 511, 'eventually': 512, 'gpt': 513, 'sorta': 514, 'specialize': 515, 'call': 516, 'gt': 517, 'influencergt': 518, 'delusional': 519, 'ChatGPT': 520, 'ExampleYou': 521, 'beginning': 522, 'blank': 523, 'capability': 524, 'counter': 525, 'face': 526, 'fix': 527, 'good': 528, 'listen': 529, 'outdo': 530, 'refined': 531, 'relationship': 532, 'reply': 533, 'send': 534, 'sort': 535, 'impressed': 536, 'Designer': 537, 'Graphic': 538, 'steal': 539, 'Ai': 540, 'informed': 541, 'little': 542, 'search': 543, 've': 544, 'Black': 545, 'DSM': 546, 'Dictionary': 547, 'Drs': 548, 'Law': 549, 'assist': 550, 'cancer': 551, 'citation': 552, 'detection': 553, 'early': 554, 'final': 555, 'furhter': 556, 'que': 557, 'questiond': 558, 'referencee': 559, 'thloowe': 560, 'correct': 561, 'es': 562, 'SOUND': 563, 'caption': 564, 'captionbthis': 565, \"didn't\": 566, 'dogive': 567, 'fantastic': 568, 'lambaste': 569, 'meyou': 570, 'photobgive': 571, 'tell': 572, 'brutal': 573, 'great': 574, 'idea': 575, 'Lmao': 576, 'tf': 577, 'matter': 578}\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(texts)\n",
    "print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11bccde2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)],\n",
       " [(6, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1)],\n",
       " [(15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1)],\n",
       " [(10, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1)],\n",
       " [(11, 1),\n",
       "  (22, 3),\n",
       "  (24, 2),\n",
       "  (29, 1),\n",
       "  (30, 1),\n",
       "  (31, 1),\n",
       "  (32, 1),\n",
       "  (33, 1),\n",
       "  (34, 1),\n",
       "  (35, 1),\n",
       "  (36, 1),\n",
       "  (37, 1)],\n",
       " [(22, 1),\n",
       "  (38, 1),\n",
       "  (39, 1),\n",
       "  (40, 1),\n",
       "  (41, 1),\n",
       "  (42, 1),\n",
       "  (43, 1),\n",
       "  (44, 1),\n",
       "  (45, 1),\n",
       "  (46, 2),\n",
       "  (47, 1),\n",
       "  (48, 1)],\n",
       " [(22, 2), (24, 1), (33, 1)],\n",
       " [(10, 1),\n",
       "  (12, 2),\n",
       "  (22, 8),\n",
       "  (33, 2),\n",
       "  (48, 1),\n",
       "  (49, 1),\n",
       "  (50, 1),\n",
       "  (51, 1),\n",
       "  (52, 1),\n",
       "  (53, 1),\n",
       "  (54, 1),\n",
       "  (55, 1),\n",
       "  (56, 1),\n",
       "  (57, 1),\n",
       "  (58, 2),\n",
       "  (59, 1),\n",
       "  (60, 1),\n",
       "  (61, 1),\n",
       "  (62, 1),\n",
       "  (63, 1),\n",
       "  (64, 1),\n",
       "  (65, 1),\n",
       "  (66, 2),\n",
       "  (67, 4),\n",
       "  (68, 1),\n",
       "  (69, 1),\n",
       "  (70, 2),\n",
       "  (71, 1),\n",
       "  (72, 1),\n",
       "  (73, 1),\n",
       "  (74, 2),\n",
       "  (75, 1),\n",
       "  (76, 1),\n",
       "  (77, 1),\n",
       "  (78, 2),\n",
       "  (79, 1),\n",
       "  (80, 2),\n",
       "  (81, 1),\n",
       "  (82, 1),\n",
       "  (83, 1),\n",
       "  (84, 1),\n",
       "  (85, 1),\n",
       "  (86, 1),\n",
       "  (87, 1),\n",
       "  (88, 1),\n",
       "  (89, 1),\n",
       "  (90, 1),\n",
       "  (91, 1),\n",
       "  (92, 1),\n",
       "  (93, 1),\n",
       "  (94, 1)],\n",
       " [(33, 1), (95, 1), (96, 1), (97, 1)],\n",
       " [(22, 1), (43, 2), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1)],\n",
       " [(22, 1),\n",
       "  (24, 1),\n",
       "  (48, 1),\n",
       "  (103, 1),\n",
       "  (104, 1),\n",
       "  (105, 1),\n",
       "  (106, 1),\n",
       "  (107, 1),\n",
       "  (108, 1),\n",
       "  (109, 1),\n",
       "  (110, 1),\n",
       "  (111, 1),\n",
       "  (112, 1)],\n",
       " [(33, 1),\n",
       "  (48, 1),\n",
       "  (102, 2),\n",
       "  (113, 1),\n",
       "  (114, 1),\n",
       "  (115, 1),\n",
       "  (116, 1),\n",
       "  (117, 1),\n",
       "  (118, 1),\n",
       "  (119, 1),\n",
       "  (120, 1)],\n",
       " [(121, 1), (122, 1), (123, 1), (124, 1), (125, 1), (126, 1)],\n",
       " [(22, 2), (127, 1), (128, 2)],\n",
       " [(12, 1),\n",
       "  (33, 1),\n",
       "  (121, 1),\n",
       "  (129, 1),\n",
       "  (130, 1),\n",
       "  (131, 1),\n",
       "  (132, 1),\n",
       "  (133, 1),\n",
       "  (134, 1),\n",
       "  (135, 1),\n",
       "  (136, 1),\n",
       "  (137, 1),\n",
       "  (138, 1)],\n",
       " [(139, 1),\n",
       "  (140, 1),\n",
       "  (141, 1),\n",
       "  (142, 1),\n",
       "  (143, 1),\n",
       "  (144, 1),\n",
       "  (145, 1),\n",
       "  (146, 1),\n",
       "  (147, 1),\n",
       "  (148, 1)],\n",
       " [(24, 1), (125, 1), (149, 1), (150, 1)],\n",
       " [(16, 1),\n",
       "  (24, 1),\n",
       "  (149, 1),\n",
       "  (151, 1),\n",
       "  (152, 2),\n",
       "  (153, 1),\n",
       "  (154, 1),\n",
       "  (155, 1),\n",
       "  (156, 1),\n",
       "  (157, 1),\n",
       "  (158, 1),\n",
       "  (159, 1),\n",
       "  (160, 1),\n",
       "  (161, 1),\n",
       "  (162, 1),\n",
       "  (163, 1),\n",
       "  (164, 1),\n",
       "  (165, 1),\n",
       "  (166, 1),\n",
       "  (167, 1),\n",
       "  (168, 1),\n",
       "  (169, 1),\n",
       "  (170, 1),\n",
       "  (171, 1),\n",
       "  (172, 1),\n",
       "  (173, 1),\n",
       "  (174, 1),\n",
       "  (175, 2),\n",
       "  (176, 1),\n",
       "  (177, 1)],\n",
       " [(137, 1),\n",
       "  (178, 1),\n",
       "  (179, 1),\n",
       "  (180, 1),\n",
       "  (181, 1),\n",
       "  (182, 1),\n",
       "  (183, 2),\n",
       "  (184, 1),\n",
       "  (185, 1),\n",
       "  (186, 1)],\n",
       " [(187, 1)],\n",
       " [(24, 1),\n",
       "  (109, 1),\n",
       "  (121, 1),\n",
       "  (188, 1),\n",
       "  (189, 1),\n",
       "  (190, 1),\n",
       "  (191, 1),\n",
       "  (192, 1),\n",
       "  (193, 1)],\n",
       " [(97, 1),\n",
       "  (128, 1),\n",
       "  (194, 1),\n",
       "  (195, 1),\n",
       "  (196, 1),\n",
       "  (197, 1),\n",
       "  (198, 1),\n",
       "  (199, 1),\n",
       "  (200, 1),\n",
       "  (201, 1),\n",
       "  (202, 1)],\n",
       " [(36, 1),\n",
       "  (72, 1),\n",
       "  (102, 1),\n",
       "  (110, 1),\n",
       "  (118, 1),\n",
       "  (121, 1),\n",
       "  (135, 1),\n",
       "  (203, 1),\n",
       "  (204, 1),\n",
       "  (205, 1),\n",
       "  (206, 1),\n",
       "  (207, 1),\n",
       "  (208, 1)],\n",
       " [(12, 2),\n",
       "  (30, 1),\n",
       "  (33, 1),\n",
       "  (48, 1),\n",
       "  (49, 1),\n",
       "  (97, 1),\n",
       "  (106, 1),\n",
       "  (207, 1),\n",
       "  (209, 1),\n",
       "  (210, 1),\n",
       "  (211, 2),\n",
       "  (212, 1),\n",
       "  (213, 1),\n",
       "  (214, 1),\n",
       "  (215, 1),\n",
       "  (216, 1),\n",
       "  (217, 1)],\n",
       " [(3, 2), (33, 1), (218, 1), (219, 1)],\n",
       " [(4, 1),\n",
       "  (125, 1),\n",
       "  (128, 1),\n",
       "  (220, 1),\n",
       "  (221, 1),\n",
       "  (222, 1),\n",
       "  (223, 1),\n",
       "  (224, 1),\n",
       "  (225, 1)],\n",
       " [(33, 1), (109, 1), (205, 1), (226, 1), (227, 1), (228, 2)],\n",
       " [(73, 1), (229, 1), (230, 1)],\n",
       " [(24, 1),\n",
       "  (33, 1),\n",
       "  (39, 1),\n",
       "  (91, 1),\n",
       "  (97, 1),\n",
       "  (231, 1),\n",
       "  (232, 1),\n",
       "  (233, 2),\n",
       "  (234, 1),\n",
       "  (235, 1),\n",
       "  (236, 1),\n",
       "  (237, 1),\n",
       "  (238, 1),\n",
       "  (239, 1),\n",
       "  (240, 1),\n",
       "  (241, 1)],\n",
       " [(3, 1),\n",
       "  (8, 2),\n",
       "  (49, 1),\n",
       "  (157, 1),\n",
       "  (242, 1),\n",
       "  (243, 1),\n",
       "  (244, 1),\n",
       "  (245, 1),\n",
       "  (246, 1),\n",
       "  (247, 1),\n",
       "  (248, 1),\n",
       "  (249, 1),\n",
       "  (250, 1),\n",
       "  (251, 1)],\n",
       " [(24, 1),\n",
       "  (33, 1),\n",
       "  (145, 1),\n",
       "  (204, 1),\n",
       "  (245, 1),\n",
       "  (252, 1),\n",
       "  (253, 1),\n",
       "  (254, 1),\n",
       "  (255, 1),\n",
       "  (256, 1),\n",
       "  (257, 1),\n",
       "  (258, 1),\n",
       "  (259, 1),\n",
       "  (260, 1),\n",
       "  (261, 1)],\n",
       " [(24, 1), (125, 1), (262, 1), (263, 1)],\n",
       " [(17, 1),\n",
       "  (24, 1),\n",
       "  (121, 2),\n",
       "  (128, 1),\n",
       "  (188, 1),\n",
       "  (264, 1),\n",
       "  (265, 1),\n",
       "  (266, 1),\n",
       "  (267, 1),\n",
       "  (268, 1),\n",
       "  (269, 1)],\n",
       " [(207, 1), (270, 1), (271, 1)],\n",
       " [(4, 2),\n",
       "  (6, 1),\n",
       "  (10, 2),\n",
       "  (22, 3),\n",
       "  (24, 3),\n",
       "  (33, 1),\n",
       "  (47, 1),\n",
       "  (81, 1),\n",
       "  (97, 1),\n",
       "  (206, 1),\n",
       "  (250, 1),\n",
       "  (272, 1),\n",
       "  (273, 1),\n",
       "  (274, 1),\n",
       "  (275, 1),\n",
       "  (276, 1),\n",
       "  (277, 1),\n",
       "  (278, 2),\n",
       "  (279, 1),\n",
       "  (280, 1),\n",
       "  (281, 1),\n",
       "  (282, 1),\n",
       "  (283, 1),\n",
       "  (284, 1),\n",
       "  (285, 1)],\n",
       " [(83, 1), (184, 1), (286, 1), (287, 1), (288, 1)],\n",
       " [(24, 1),\n",
       "  (47, 1),\n",
       "  (97, 1),\n",
       "  (121, 2),\n",
       "  (271, 1),\n",
       "  (284, 1),\n",
       "  (289, 1),\n",
       "  (290, 1),\n",
       "  (291, 1),\n",
       "  (292, 1)],\n",
       " [(6, 1), (33, 1), (73, 1), (293, 1), (294, 1), (295, 1)],\n",
       " [(12, 1), (229, 1), (230, 1), (244, 1), (296, 1)],\n",
       " [(22, 1),\n",
       "  (78, 1),\n",
       "  (81, 1),\n",
       "  (90, 1),\n",
       "  (121, 1),\n",
       "  (130, 1),\n",
       "  (135, 1),\n",
       "  (297, 1),\n",
       "  (298, 1),\n",
       "  (299, 1),\n",
       "  (300, 1),\n",
       "  (301, 1),\n",
       "  (302, 1),\n",
       "  (303, 1),\n",
       "  (304, 1),\n",
       "  (305, 1),\n",
       "  (306, 1),\n",
       "  (307, 1),\n",
       "  (308, 1)],\n",
       " [(22, 1), (106, 1), (112, 1), (309, 1), (310, 1), (311, 1)],\n",
       " [(149, 1), (199, 1), (201, 1)],\n",
       " [(22, 4),\n",
       "  (28, 1),\n",
       "  (86, 1),\n",
       "  (109, 1),\n",
       "  (128, 2),\n",
       "  (168, 1),\n",
       "  (207, 1),\n",
       "  (312, 1),\n",
       "  (313, 1),\n",
       "  (314, 1),\n",
       "  (315, 2),\n",
       "  (316, 1),\n",
       "  (317, 1),\n",
       "  (318, 2),\n",
       "  (319, 1),\n",
       "  (320, 1),\n",
       "  (321, 1)],\n",
       " [(322, 1), (323, 1), (324, 1)],\n",
       " [(22, 1), (128, 1), (325, 1), (326, 1), (327, 1), (328, 1), (329, 1)],\n",
       " [(48, 1),\n",
       "  (134, 1),\n",
       "  (137, 1),\n",
       "  (229, 1),\n",
       "  (330, 1),\n",
       "  (331, 1),\n",
       "  (332, 1),\n",
       "  (333, 1),\n",
       "  (334, 1)],\n",
       " [(97, 1), (285, 1)],\n",
       " [(12, 1),\n",
       "  (22, 1),\n",
       "  (24, 2),\n",
       "  (33, 1),\n",
       "  (121, 1),\n",
       "  (128, 1),\n",
       "  (239, 1),\n",
       "  (335, 1),\n",
       "  (336, 1),\n",
       "  (337, 1),\n",
       "  (338, 1),\n",
       "  (339, 1),\n",
       "  (340, 1),\n",
       "  (341, 1),\n",
       "  (342, 3),\n",
       "  (343, 1),\n",
       "  (344, 1),\n",
       "  (345, 1),\n",
       "  (346, 1)],\n",
       " [(347, 1), (348, 1), (349, 1), (350, 1), (351, 1), (352, 1), (353, 1)],\n",
       " [(22, 1),\n",
       "  (33, 1),\n",
       "  (84, 1),\n",
       "  (102, 1),\n",
       "  (271, 2),\n",
       "  (321, 1),\n",
       "  (354, 1),\n",
       "  (355, 1),\n",
       "  (356, 1),\n",
       "  (357, 1),\n",
       "  (358, 1)],\n",
       " [(22, 2), (24, 1), (269, 1), (359, 1), (360, 1)],\n",
       " [(18, 1), (41, 1), (130, 1), (238, 1)],\n",
       " [(4, 1),\n",
       "  (12, 1),\n",
       "  (22, 1),\n",
       "  (43, 2),\n",
       "  (48, 1),\n",
       "  (102, 3),\n",
       "  (140, 1),\n",
       "  (147, 1),\n",
       "  (175, 1),\n",
       "  (176, 1),\n",
       "  (251, 1),\n",
       "  (271, 1),\n",
       "  (321, 1),\n",
       "  (361, 1),\n",
       "  (362, 1),\n",
       "  (363, 1),\n",
       "  (364, 1),\n",
       "  (365, 2),\n",
       "  (366, 1),\n",
       "  (367, 1),\n",
       "  (368, 1),\n",
       "  (369, 1),\n",
       "  (370, 2)],\n",
       " [(12, 1),\n",
       "  (24, 1),\n",
       "  (121, 1),\n",
       "  (128, 1),\n",
       "  (245, 1),\n",
       "  (371, 1),\n",
       "  (372, 1),\n",
       "  (373, 1),\n",
       "  (374, 1)],\n",
       " [(48, 1), (97, 1), (103, 1)],\n",
       " [(12, 1),\n",
       "  (22, 1),\n",
       "  (103, 1),\n",
       "  (236, 1),\n",
       "  (248, 1),\n",
       "  (344, 1),\n",
       "  (375, 1),\n",
       "  (376, 1),\n",
       "  (377, 1),\n",
       "  (378, 1),\n",
       "  (379, 1),\n",
       "  (380, 1),\n",
       "  (381, 1),\n",
       "  (382, 1),\n",
       "  (383, 1),\n",
       "  (384, 1)],\n",
       " [(103, 1), (385, 1), (386, 1)],\n",
       " [(110, 1),\n",
       "  (121, 1),\n",
       "  (184, 1),\n",
       "  (380, 2),\n",
       "  (387, 1),\n",
       "  (388, 1),\n",
       "  (389, 1),\n",
       "  (390, 1),\n",
       "  (391, 1),\n",
       "  (392, 1),\n",
       "  (393, 1),\n",
       "  (394, 1),\n",
       "  (395, 1),\n",
       "  (396, 1)],\n",
       " [(149, 1), (248, 1), (341, 1), (397, 1), (398, 1), (399, 1), (400, 1)],\n",
       " [(263, 1), (401, 1)],\n",
       " [(402, 1)],\n",
       " [(341, 1), (380, 1), (403, 1), (404, 1), (405, 1)],\n",
       " [(24, 1),\n",
       "  (49, 1),\n",
       "  (121, 1),\n",
       "  (128, 1),\n",
       "  (248, 1),\n",
       "  (406, 1),\n",
       "  (407, 1),\n",
       "  (408, 1),\n",
       "  (409, 1)],\n",
       " [(12, 1),\n",
       "  (33, 1),\n",
       "  (73, 1),\n",
       "  (128, 1),\n",
       "  (146, 1),\n",
       "  (337, 1),\n",
       "  (410, 1),\n",
       "  (411, 1),\n",
       "  (412, 1),\n",
       "  (413, 1),\n",
       "  (414, 1)],\n",
       " [(415, 1), (416, 1)],\n",
       " [(103, 1)],\n",
       " [(22, 1),\n",
       "  (46, 1),\n",
       "  (102, 2),\n",
       "  (170, 1),\n",
       "  (205, 1),\n",
       "  (409, 1),\n",
       "  (417, 1),\n",
       "  (418, 1),\n",
       "  (419, 1),\n",
       "  (420, 1),\n",
       "  (421, 1)],\n",
       " [(33, 1),\n",
       "  (48, 1),\n",
       "  (106, 1),\n",
       "  (128, 1),\n",
       "  (192, 1),\n",
       "  (204, 1),\n",
       "  (422, 1),\n",
       "  (423, 1),\n",
       "  (424, 2),\n",
       "  (425, 1),\n",
       "  (426, 1),\n",
       "  (427, 1)],\n",
       " [(48, 1),\n",
       "  (109, 1),\n",
       "  (121, 1),\n",
       "  (130, 2),\n",
       "  (137, 1),\n",
       "  (139, 1),\n",
       "  (321, 1),\n",
       "  (379, 1),\n",
       "  (428, 1),\n",
       "  (429, 3),\n",
       "  (430, 1),\n",
       "  (431, 1),\n",
       "  (432, 1)],\n",
       " [(6, 1),\n",
       "  (33, 1),\n",
       "  (200, 1),\n",
       "  (245, 1),\n",
       "  (341, 1),\n",
       "  (412, 1),\n",
       "  (433, 1),\n",
       "  (434, 1),\n",
       "  (435, 1),\n",
       "  (436, 1)],\n",
       " [(33, 1), (38, 1), (188, 1), (437, 1), (438, 1), (439, 1)],\n",
       " [(0, 1), (12, 1), (24, 1), (90, 1), (125, 1), (440, 1)],\n",
       " [(22, 1), (24, 1), (441, 1), (442, 1), (443, 1)],\n",
       " [(6, 1), (113, 1), (444, 1), (445, 1), (446, 1), (447, 1)],\n",
       " [(116, 1),\n",
       "  (151, 1),\n",
       "  (267, 1),\n",
       "  (409, 1),\n",
       "  (448, 1),\n",
       "  (449, 1),\n",
       "  (450, 1),\n",
       "  (451, 1),\n",
       "  (452, 1),\n",
       "  (453, 1)],\n",
       " [(12, 2),\n",
       "  (22, 2),\n",
       "  (24, 1),\n",
       "  (127, 1),\n",
       "  (130, 3),\n",
       "  (135, 2),\n",
       "  (297, 1),\n",
       "  (355, 1),\n",
       "  (428, 1),\n",
       "  (454, 2),\n",
       "  (455, 1),\n",
       "  (456, 1),\n",
       "  (457, 1),\n",
       "  (458, 1),\n",
       "  (459, 1),\n",
       "  (460, 1),\n",
       "  (461, 1)],\n",
       " [(12, 1),\n",
       "  (22, 2),\n",
       "  (24, 1),\n",
       "  (34, 2),\n",
       "  (40, 1),\n",
       "  (48, 1),\n",
       "  (49, 1),\n",
       "  (109, 1),\n",
       "  (127, 1),\n",
       "  (223, 1),\n",
       "  (254, 1),\n",
       "  (282, 1),\n",
       "  (323, 1),\n",
       "  (462, 1),\n",
       "  (463, 1),\n",
       "  (464, 1),\n",
       "  (465, 1),\n",
       "  (466, 1),\n",
       "  (467, 1),\n",
       "  (468, 1),\n",
       "  (469, 1),\n",
       "  (470, 1),\n",
       "  (471, 1),\n",
       "  (472, 1),\n",
       "  (473, 1),\n",
       "  (474, 1),\n",
       "  (475, 1),\n",
       "  (476, 1)],\n",
       " [(0, 1), (10, 1), (245, 1), (339, 1), (477, 1)],\n",
       " [(248, 1), (404, 1), (478, 1), (479, 1), (480, 1)],\n",
       " [(12, 1),\n",
       "  (24, 3),\n",
       "  (30, 1),\n",
       "  (138, 1),\n",
       "  (140, 1),\n",
       "  (168, 1),\n",
       "  (192, 1),\n",
       "  (200, 1),\n",
       "  (227, 1),\n",
       "  (324, 1),\n",
       "  (408, 2),\n",
       "  (459, 1),\n",
       "  (481, 1),\n",
       "  (482, 1),\n",
       "  (483, 1),\n",
       "  (484, 1),\n",
       "  (485, 1),\n",
       "  (486, 1),\n",
       "  (487, 1),\n",
       "  (488, 1),\n",
       "  (489, 1),\n",
       "  (490, 2),\n",
       "  (491, 1),\n",
       "  (492, 1),\n",
       "  (493, 1),\n",
       "  (494, 1),\n",
       "  (495, 1)],\n",
       " [(496, 1)],\n",
       " [(22, 1), (24, 1), (110, 1), (127, 1), (497, 1), (498, 1), (499, 1)],\n",
       " [(354, 1), (500, 1), (501, 1)],\n",
       " [(184, 1), (502, 1), (503, 1)],\n",
       " [(0, 1),\n",
       "  (4, 1),\n",
       "  (12, 1),\n",
       "  (47, 1),\n",
       "  (379, 1),\n",
       "  (504, 2),\n",
       "  (505, 1),\n",
       "  (506, 1),\n",
       "  (507, 1),\n",
       "  (508, 1),\n",
       "  (509, 1)],\n",
       " [(24, 1), (188, 1), (192, 1), (445, 1), (510, 1)],\n",
       " [(24, 1), (121, 1), (511, 1), (512, 1), (513, 1), (514, 1), (515, 1)],\n",
       " [(24, 1), (516, 1), (517, 1), (518, 1)],\n",
       " [(18, 1),\n",
       "  (22, 1),\n",
       "  (33, 1),\n",
       "  (47, 1),\n",
       "  (106, 1),\n",
       "  (109, 1),\n",
       "  (112, 1),\n",
       "  (128, 1),\n",
       "  (192, 1),\n",
       "  (519, 1)],\n",
       " [(4, 1),\n",
       "  (12, 1),\n",
       "  (24, 2),\n",
       "  (97, 1),\n",
       "  (102, 1),\n",
       "  (106, 1),\n",
       "  (110, 2),\n",
       "  (130, 2),\n",
       "  (135, 2),\n",
       "  (148, 1),\n",
       "  (225, 1),\n",
       "  (236, 1),\n",
       "  (263, 1),\n",
       "  (274, 1),\n",
       "  (291, 4),\n",
       "  (297, 1),\n",
       "  (416, 1),\n",
       "  (429, 1),\n",
       "  (437, 1),\n",
       "  (440, 1),\n",
       "  (520, 1),\n",
       "  (521, 1),\n",
       "  (522, 1),\n",
       "  (523, 1),\n",
       "  (524, 1),\n",
       "  (525, 1),\n",
       "  (526, 1),\n",
       "  (527, 1),\n",
       "  (528, 1),\n",
       "  (529, 1),\n",
       "  (530, 1),\n",
       "  (531, 1),\n",
       "  (532, 1),\n",
       "  (533, 1),\n",
       "  (534, 1),\n",
       "  (535, 1)],\n",
       " [(204, 1), (341, 1), (536, 1)],\n",
       " [(4, 1), (22, 1), (24, 1), (106, 1), (112, 1), (537, 1), (538, 1), (539, 1)],\n",
       " [(97, 2),\n",
       "  (109, 1),\n",
       "  (142, 2),\n",
       "  (145, 1),\n",
       "  (147, 1),\n",
       "  (271, 2),\n",
       "  (297, 1),\n",
       "  (355, 1),\n",
       "  (540, 1),\n",
       "  (541, 1),\n",
       "  (542, 1),\n",
       "  (543, 1),\n",
       "  (544, 1)],\n",
       " [(15, 1),\n",
       "  (22, 2),\n",
       "  (33, 1),\n",
       "  (49, 2),\n",
       "  (121, 2),\n",
       "  (130, 2),\n",
       "  (135, 1),\n",
       "  (137, 1),\n",
       "  (140, 1),\n",
       "  (142, 1),\n",
       "  (263, 1),\n",
       "  (306, 1),\n",
       "  (337, 1),\n",
       "  (355, 2),\n",
       "  (545, 1),\n",
       "  (546, 1),\n",
       "  (547, 1),\n",
       "  (548, 1),\n",
       "  (549, 1),\n",
       "  (550, 1),\n",
       "  (551, 1),\n",
       "  (552, 1),\n",
       "  (553, 1),\n",
       "  (554, 1),\n",
       "  (555, 1),\n",
       "  (556, 1),\n",
       "  (557, 1),\n",
       "  (558, 1),\n",
       "  (559, 1),\n",
       "  (560, 1)],\n",
       " [(22, 1), (24, 1), (297, 1), (561, 1)],\n",
       " [(205, 1),\n",
       "  (224, 1),\n",
       "  (226, 1),\n",
       "  (227, 1),\n",
       "  (228, 2),\n",
       "  (379, 1),\n",
       "  (448, 1),\n",
       "  (528, 1),\n",
       "  (562, 1)],\n",
       " [(12, 2),\n",
       "  (22, 1),\n",
       "  (130, 1),\n",
       "  (171, 1),\n",
       "  (528, 1),\n",
       "  (563, 1),\n",
       "  (564, 1),\n",
       "  (565, 1),\n",
       "  (566, 1),\n",
       "  (567, 1),\n",
       "  (568, 1),\n",
       "  (569, 1),\n",
       "  (570, 1),\n",
       "  (571, 1),\n",
       "  (572, 1)],\n",
       " [(90, 1),\n",
       "  (102, 1),\n",
       "  (221, 1),\n",
       "  (233, 1),\n",
       "  (236, 1),\n",
       "  (573, 1),\n",
       "  (574, 1),\n",
       "  (575, 1)],\n",
       " [(12, 1), (229, 1), (230, 1), (576, 1), (577, 1)],\n",
       " [(47, 1), (578, 1)]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54a7f711",
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing your generated corpus\n",
    "\n",
    "corpora.MmCorpus.serialize('miniDictionary.mm', corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4767450d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.2908583401148543), (1, 0.41612420892246005), (2, 0.41612420892246005), (3, 0.3168533565823045), (4, 0.240291332241033), (5, 0.41612420892246005), (6, 0.2542204221785016), (7, 0.41612420892246005)]\n",
      "[(6, 0.263429758834572), (8, 0.36629677662635135), (9, 0.4311986388123495), (10, 0.2805011815921728), (11, 0.36629677662635135), (12, 0.16056274104279267), (13, 0.4311986388123495), (14, 0.4311986388123495)]\n",
      "[(15, 0.35442421902756727), (16, 0.35442421902756727), (17, 0.35442421902756727), (18, 0.3176896052267887), (19, 0.4172224561034334), (20, 0.4172224561034334), (21, 0.4172224561034334)]\n",
      "[(10, 0.28274023599862347), (22, 0.12014378546935142), (23, 0.4346406108097868), (24, 0.11683183128288098), (25, 0.4346406108097868), (26, 0.4346406108097868), (27, 0.4346406108097868), (28, 0.3692206802160566)]\n",
      "[(11, 0.28577409126192943), (22, 0.2789712192706615), (24, 0.1808539564782505), (29, 0.3364086364474857), (30, 0.2561547810873081), (31, 0.3364086364474857), (32, 0.3364086364474857), (33, 0.1140056414344887), (34, 0.28577409126192943), (35, 0.3364086364474857), (36, 0.28577409126192943), (37, 0.3364086364474857)]\n",
      "[(22, 0.08727178209646984), (38, 0.2681998625517423), (39, 0.2681998625517423), (40, 0.2681998625517423), (41, 0.2681998625517423), (42, 0.3157205387584916), (43, 0.24040204896188194), (44, 0.3157205387584916), (45, 0.3157205387584916), (46, 0.5363997251034845), (47, 0.19288137275513262), (48, 0.15132600894983808)]\n",
      "[(22, 0.7875793969502054), (24, 0.3829342602569832), (33, 0.48278364286809455)]\n",
      "[(10, 0.07228755919392185), (12, 0.08275678969755253), (22, 0.2457351278136408), (33, 0.07531742237413247), (48, 0.05326194111303818), (49, 0.06788810719835503), (50, 0.11112358582790378), (51, 0.11112358582790378), (52, 0.11112358582790378), (53, 0.11112358582790378), (54, 0.11112358582790378), (55, 0.11112358582790378), (56, 0.11112358582790378), (57, 0.11112358582790378), (58, 0.22224717165580757), (59, 0.11112358582790378), (60, 0.11112358582790378), (61, 0.11112358582790378), (62, 0.11112358582790378), (63, 0.11112358582790378), (64, 0.11112358582790378), (65, 0.11112358582790378), (66, 0.22224717165580757), (67, 0.44449434331161514), (68, 0.11112358582790378), (69, 0.11112358582790378), (70, 0.22224717165580757), (71, 0.11112358582790378), (72, 0.0943978195479338), (73, 0.07767205326796385), (74, 0.22224717165580757), (75, 0.11112358582790378), (76, 0.11112358582790378), (77, 0.11112358582790378), (78, 0.1887956390958676), (79, 0.11112358582790378), (80, 0.22224717165580757), (81, 0.08461387347832501), (82, 0.11112358582790378), (83, 0.0943978195479338), (84, 0.0943978195479338), (85, 0.11112358582790378), (86, 0.0943978195479338), (87, 0.11112358582790378), (88, 0.11112358582790378), (89, 0.11112358582790378), (90, 0.07767205326796385), (91, 0.0943978195479338), (92, 0.11112358582790378), (93, 0.11112358582790378), (94, 0.11112358582790378)]\n",
      "[(33, 0.22037265899483854), (95, 0.6502771686553852), (96, 0.6502771686553852), (97, 0.3251385843276926)]\n",
      "[(22, 0.1068196748180626), (43, 0.588498781136794), (98, 0.3864383707242961), (99, 0.3864383707242961), (100, 0.3864383707242961), (101, 0.3864383707242961), (102, 0.21194405912899988)]\n",
      "[(22, 0.10197644371845006), (24, 0.09916530114977475), (48, 0.17682334271291394), (103, 0.23998614369122032), (104, 0.3689171571616891), (105, 0.3689171571616891), (106, 0.21303157393920158), (107, 0.3689171571616891), (108, 0.3689171571616891), (109, 0.2023344618305618), (110, 0.23998614369122032), (111, 0.3689171571616891), (112, 0.2578620269409375)]\n",
      "[(33, 0.11481105534807952), (48, 0.16238101295339538), (102, 0.3716169411045437), (113, 0.2877929951192301), (114, 0.33878525740270937), (115, 0.33878525740270937), (116, 0.2877929951192301), (117, 0.33878525740270937), (118, 0.2877929951192301), (119, 0.33878525740270937), (120, 0.33878525740270937)]\n",
      "[(121, 0.19894223893130072), (122, 0.4659767441581767), (123, 0.4659767441581767), (124, 0.4659767441581767), (125, 0.30312486071581435), (126, 0.4659767441581767)]\n",
      "[(22, 0.4314208596654125), (127, 0.5454546818923716), (128, 0.7185786191136277)]\n",
      "[(12, 0.13184651410407217), (33, 0.1199942582067934), (121, 0.1511694448754544), (129, 0.35407988830159004), (130, 0.19419688744139418), (131, 0.35407988830159004), (132, 0.35407988830159004), (133, 0.35407988830159004), (134, 0.30078555468152474), (135, 0.21631603439279845), (136, 0.35407988830159004), (137, 0.23033427777086032), (138, 0.30078555468152474)]\n",
      "[(139, 0.3124288607586506), (140, 0.2570715216888326), (141, 0.3677861998284687), (142, 0.28004689326310095), (143, 0.3677861998284687), (144, 0.3677861998284687), (145, 0.28004689326310095), (146, 0.3124288607586506), (147, 0.28004689326310095), (148, 0.3124288607586506)]\n",
      "[(24, 0.19083671386028786), (125, 0.4618366152578297), (149, 0.4962375072752281), (150, 0.7099553688954438)]\n",
      "[(16, 0.15170136793069944), (24, 0.048002589164535564), (149, 0.1248223400409483), (151, 0.15170136793069944), (152, 0.35716079164090125), (153, 0.17858039582045063), (154, 0.17858039582045063), (155, 0.17858039582045063), (156, 0.17858039582045063), (157, 0.15170136793069944), (158, 0.17858039582045063), (159, 0.17858039582045063), (160, 0.17858039582045063), (161, 0.17858039582045063), (162, 0.17858039582045063), (163, 0.17858039582045063), (164, 0.17858039582045063), (165, 0.17858039582045063), (166, 0.17858039582045063), (167, 0.17858039582045063), (168, 0.13597814455935694), (169, 0.17858039582045063), (170, 0.15170136793069944), (171, 0.15170136793069944), (172, 0.17858039582045063), (173, 0.17858039582045063), (174, 0.17858039582045063), (175, 0.3034027358613989), (176, 0.15170136793069944), (177, 0.17858039582045063)]\n",
      "[(137, 0.18848201443993842), (178, 0.28974276545214706), (179, 0.28974276545214706), (180, 0.28974276545214706), (181, 0.28974276545214706), (182, 0.28974276545214706), (183, 0.5794855309042941), (184, 0.2025215020244173), (185, 0.28974276545214706), (186, 0.28974276545214706)]\n",
      "[(187, 1.0)]\n",
      "[(24, 0.11496190725518611), (109, 0.23456547164981686), (121, 0.18259372023639153), (188, 0.2989383391378497), (189, 0.42768407411391557), (190, 0.42768407411391557), (191, 0.42768407411391557), (192, 0.27821490454499065), (193, 0.42768407411391557)]\n",
      "[(97, 0.17164994362649783), (128, 0.15805848720614718), (194, 0.34329988725299565), (195, 0.34329988725299565), (196, 0.34329988725299565), (197, 0.34329988725299565), (198, 0.34329988725299565), (199, 0.2916281054673884), (200, 0.2614020507773617), (201, 0.2916281054673884), (202, 0.34329988725299565)]\n",
      "[(36, 0.307500934902702), (72, 0.307500934902702), (102, 0.19853255422006952), (110, 0.23547675296332538), (118, 0.307500934902702), (121, 0.15454447497368443), (135, 0.2211455363295619), (203, 0.36198512524401827), (204, 0.25301674456138573), (205, 0.25301674456138573), (206, 0.307500934902702), (207, 0.25301674456138573), (208, 0.36198512524401827)]\n",
      "[(12, 0.19277534775674796), (30, 0.1971012764564981), (33, 0.0877229671630475), (48, 0.12406944805120955), (49, 0.15813993657244682), (97, 0.12942676957528548), (106, 0.14947522985712033), (207, 0.18093085938246836), (209, 0.25885353915057097), (210, 0.25885353915057097), (211, 0.5177070783011419), (212, 0.25885353915057097), (213, 0.25885353915057097), (214, 0.25885353915057097), (215, 0.25885353915057097), (216, 0.25885353915057097), (217, 0.25885353915057097)]\n",
      "[(3, 0.7232145754992697), (33, 0.16093890815659448), (218, 0.4748996449918522), (219, 0.4748996449918522)]\n",
      "[(4, 0.23864269223134155), (125, 0.2688377988749936), (128, 0.19027300508089603), (220, 0.4132691786829897), (221, 0.3510659691494909), (222, 0.4132691786829897), (223, 0.3510659691494909), (224, 0.3510659691494909), (225, 0.3510659691494909)]\n",
      "[(33, 0.15017920078414088), (109, 0.24304774067152174), (205, 0.30974843576304445), (226, 0.37644913085456716), (227, 0.33743172545399075), (228, 0.7528982617091343)]\n",
      "[(73, 0.5601792998360362), (229, 0.5601792998360362), (230, 0.6102444625479335)]\n",
      "[(24, 0.07262595767853462), (33, 0.09156303849986379), (39, 0.2295179764022086), (91, 0.2295179764022086), (97, 0.1350924241254674), (231, 0.2701848482509348), (232, 0.2701848482509348), (233, 0.4590359528044172), (234, 0.2701848482509348), (235, 0.2701848482509348), (236, 0.18885110455348245), (237, 0.2701848482509348), (238, 0.2295179764022086), (239, 0.2295179764022086), (240, 0.2701848482509348), (241, 0.2701848482509348)]\n",
      "[(3, 0.21474694358879326), (8, 0.4791564880801275), (49, 0.17229755508840577), (157, 0.23957824404006375), (242, 0.28202763254045127), (243, 0.28202763254045127), (244, 0.23957824404006375), (245, 0.1834632047706131), (246, 0.28202763254045127), (247, 0.28202763254045127), (248, 0.1834632047706131), (249, 0.28202763254045127), (250, 0.23957824404006375), (251, 0.23957824404006375)]\n",
      "[(24, 0.07961113310340343), (33, 0.10036958517820935), (145, 0.22551646388413174), (204, 0.20701483191285613), (245, 0.19266385123479898), (252, 0.29617126719122705), (253, 0.29617126719122705), (254, 0.2515930495520416), (255, 0.29617126719122705), (256, 0.29617126719122705), (257, 0.29617126719122705), (258, 0.29617126719122705), (259, 0.29617126719122705), (260, 0.29617126719122705), (261, 0.29617126719122705)]\n",
      "[(24, 0.19083671386028786), (125, 0.4618366152578297), (262, 0.7099553688954438), (263, 0.4962375072752281)]\n",
      "[(17, 0.30679603299367636), (24, 0.09707891319630267), (121, 0.30838040774099945), (128, 0.16627929869142993), (188, 0.2524367398654221), (264, 0.36115532612193063), (265, 0.36115532612193063), (266, 0.36115532612193063), (267, 0.30679603299367636), (268, 0.36115532612193063), (269, 0.30679603299367636)]\n",
      "[(207, 0.5055282082622798), (270, 0.723247357005688), (271, 0.47048325287454806)]\n",
      "[(4, 0.23882171079101203), (6, 0.12633280521700704), (10, 0.2690394683880618), (22, 0.17148295179127432), (24, 0.1667557519791933), (33, 0.07007899942207316), (47, 0.12633280521700704), (81, 0.1574577409495477), (97, 0.10339479846149027), (206, 0.17566466119043989), (250, 0.17566466119043989), (272, 0.20678959692298055), (273, 0.20678959692298055), (274, 0.17566466119043989), (275, 0.20678959692298055), (276, 0.20678959692298055), (277, 0.20678959692298055), (278, 0.4135791938459611), (279, 0.20678959692298055), (280, 0.20678959692298055), (281, 0.20678959692298055), (282, 0.17566466119043989), (283, 0.20678959692298055), (284, 0.17566466119043989), (285, 0.17566466119043989)]\n",
      "[(83, 0.4140046184558339), (184, 0.34064969860406513), (286, 0.4873595383076027), (287, 0.4873595383076027), (288, 0.4873595383076027)]\n",
      "[(24, 0.10716946599755967), (47, 0.24357215470629778), (97, 0.19934722262700363), (121, 0.34043400913321437), (271, 0.2593567161900372), (284, 0.3386849516909736), (289, 0.39869444525400727), (290, 0.39869444525400727), (291, 0.3386849516909736), (292, 0.39869444525400727)]\n",
      "[(6, 0.3063582812555231), (33, 0.16994225512664318), (73, 0.3505102399045443), (293, 0.5014667835961127), (294, 0.5014667835961127), (295, 0.5014667835961127)]\n",
      "[(12, 0.21758815470858028), (229, 0.40843823944279045), (230, 0.44494177843726845), (244, 0.4963906270171791), (296, 0.5843430145915679)]\n",
      "[(22, 0.07422875788932701), (78, 0.22811660521951627), (81, 0.2044732565305492), (90, 0.18769803367036741), (121, 0.11464732943847583), (130, 0.14727946212121862), (135, 0.16405468498140033), (297, 0.1746861599334814), (298, 0.2685351767686651), (299, 0.2685351767686651), (300, 0.2685351767686651), (301, 0.2685351767686651), (302, 0.2685351767686651), (303, 0.2685351767686651), (304, 0.2685351767686651), (305, 0.2685351767686651), (306, 0.22811660521951627), (307, 0.2685351767686651), (308, 0.2685351767686651)]\n",
      "[(22, 0.13999961728501564), (106, 0.2924630211998339), (112, 0.3540090609919765), (309, 0.5064724649067949), (310, 0.5064724649067949), (311, 0.5064724649067949)]\n",
      "[(149, 0.5028940423634344), (199, 0.6111863799837839), (201, 0.6111863799837839)]\n",
      "[(22, 0.2449742929773005), (28, 0.18821109792566015), (86, 0.18821109792566015), (109, 0.12151517528090809), (128, 0.2040157368636372), (168, 0.16870379107657069), (207, 0.1548631366032841), (312, 0.22155905924803623), (313, 0.22155905924803623), (314, 0.22155905924803623), (315, 0.44311811849607247), (316, 0.22155905924803623), (317, 0.22155905924803623), (318, 0.44311811849607247), (319, 0.22155905924803623), (320, 0.22155905924803623), (321, 0.1548631366032841)]\n",
      "[(322, 0.6397585333031344), (323, 0.5434652790500155), (324, 0.5434652790500155)]\n",
      "[(22, 0.1202013823523374), (128, 0.2002085467385121), (325, 0.4348489773458), (326, 0.4348489773458), (327, 0.4348489773458), (328, 0.4348489773458), (329, 0.4348489773458)]\n",
      "[(48, 0.1829578446210804), (134, 0.3242619634302414), (137, 0.24831194182296085), (229, 0.26680799002501465), (330, 0.38171593683546823), (331, 0.38171593683546823), (332, 0.38171593683546823), (333, 0.38171593683546823), (334, 0.38171593683546823)]\n",
      "[(97, 0.5072484348076326), (285, 0.8617998754845622)]\n",
      "[(12, 0.08288881532564665), (22, 0.061531790028375874), (24, 0.1196711370970202), (33, 0.07543757964499467), (121, 0.09503668932249043), (128, 0.10248792500314242), (239, 0.1890968332688673), (335, 0.2226017325629819), (336, 0.2226017325629819), (337, 0.16949772359137158), (338, 0.2226017325629819), (339, 0.1890968332688673), (340, 0.2226017325629819), (341, 0.1448057655756055), (342, 0.6678051976889458), (343, 0.2226017325629819), (344, 0.1890968332688673), (345, 0.2226017325629819), (346, 0.2226017325629819)]\n",
      "[(347, 0.37796447300922725), (348, 0.37796447300922725), (349, 0.37796447300922725), (350, 0.37796447300922725), (351, 0.37796447300922725), (352, 0.37796447300922725), (353, 0.37796447300922725)]\n",
      "[(22, 0.10023477186419427), (33, 0.12288718696816713), (84, 0.30803716150961435), (102, 0.19887875946963976), (271, 0.47177476456957634), (321, 0.25345796048962704), (354, 0.30803716150961435), (355, 0.25345796048962704), (356, 0.3626163625296017), (357, 0.3626163625296017), (358, 0.3626163625296017)]\n",
      "[(22, 0.31401780566632786), (24, 0.1526807031595813), (269, 0.48251296292662477), (359, 0.568006452962891), (360, 0.568006452962891)]\n",
      "[(18, 0.499495981439723), (41, 0.5572529608036857), (130, 0.3597805440495911), (238, 0.5572529608036857)]\n",
      "[(4, 0.11335741476559301), (12, 0.07309744588829663), (22, 0.05426325221730566), (43, 0.2989510859754366), (48, 0.09409045161477769), (102, 0.3229959449716959), (140, 0.13721239626470896), (147, 0.1494755429877183), (175, 0.16675947753885262), (176, 0.16675947753885262), (251, 0.16675947753885262), (271, 0.12770036068064183), (321, 0.13721239626470896), (361, 0.19630655881299633), (362, 0.19630655881299633), (363, 0.19630655881299633), (364, 0.19630655881299633), (365, 0.39261311762599266), (366, 0.19630655881299633), (367, 0.19630655881299633), (368, 0.19630655881299633), (369, 0.19630655881299633), (370, 0.39261311762599266)]\n",
      "[(12, 0.16605636330241147), (24, 0.11987234791885623), (121, 0.19039296130838704), (128, 0.20532048915852144), (245, 0.29009847374747705), (371, 0.445952014502825), (372, 0.445952014502825), (373, 0.445952014502825), (374, 0.445952014502825)]\n",
      "[(48, 0.5044179044360794), (97, 0.5261986807594277), (103, 0.6846002673468308)]\n",
      "[(12, 0.11057631097470513), (22, 0.08208536124297504), (103, 0.1931754881802986), (236, 0.20756457923491048), (248, 0.1931754881802986), (344, 0.2522611785163321), (375, 0.29695777779775384), (376, 0.29695777779775384), (377, 0.29695777779775384), (378, 0.29695777779775384), (379, 0.20756457923491048), (380, 0.22611534402694033), (381, 0.29695777779775384), (382, 0.29695777779775384), (383, 0.29695777779775384), (384, 0.29695777779775384)]\n",
      "[(103, 0.417893285631969), (385, 0.6424037678219663), (386, 0.6424037678219663)]\n",
      "[(110, 0.17761993849724111), (121, 0.1165727817904365), (184, 0.19085034103033033), (380, 0.4158145930177463), (387, 0.2730451090124063), (388, 0.2730451090124063), (389, 0.2730451090124063), (390, 0.2730451090124063), (391, 0.2730451090124063), (392, 0.2730451090124063), (393, 0.2730451090124063), (394, 0.2730451090124063), (395, 0.2730451090124063), (396, 0.2730451090124063)]\n",
      "[(149, 0.3026184862388888), (248, 0.28163993118218955), (341, 0.28163993118218955), (397, 0.432949174301634), (398, 0.432949174301634), (399, 0.432949174301634), (400, 0.432949174301634)]\n",
      "[(263, 0.5728956208844553), (401, 0.819628335022292)]\n",
      "[(402, 1.0)]\n",
      "[(341, 0.33706868051065786), (380, 0.3945448844070649), (403, 0.5181566630039682), (404, 0.44016631399529443), (405, 0.5181566630039682)]\n",
      "[(24, 0.12581804350531636), (49, 0.28595618791474103), (121, 0.19983649527929612), (128, 0.21550443188921709), (248, 0.3044874237008622), (406, 0.4680713353506764), (407, 0.4680713353506764), (408, 0.39761957932515235), (409, 0.3564079439402651)]\n",
      "[(12, 0.1409712797139637), (33, 0.12829875899780804), (73, 0.26461946596074504), (128, 0.17430402263755612), (146, 0.3216021663603416), (337, 0.2882694234367492), (410, 0.3785848667599382), (411, 0.3785848667599382), (412, 0.3216021663603416), (413, 0.3785848667599382), (414, 0.3785848667599382)]\n",
      "[(415, 0.7621329686231696), (416, 0.6474205265031646)]\n",
      "[(103, 1.0)]\n",
      "[(22, 0.09322802158501661), (46, 0.2865043198892546), (102, 0.3699529202452372), (170, 0.2865043198892546), (205, 0.23574039000593658), (409, 0.25680932451827554), (417, 0.3372682497725727), (418, 0.3372682497725727), (419, 0.3372682497725727), (420, 0.3372682497725727), (421, 0.3372682497725727)]\n",
      "[(33, 0.10311277339055552), (48, 0.14583575197379628), (106, 0.17569863403173794), (128, 0.14008686699452524), (192, 0.19792952215208057), (204, 0.21267272763570763), (422, 0.3042658859699344), (423, 0.3042658859699344), (424, 0.6085317719398688), (425, 0.3042658859699344), (426, 0.3042658859699344), (427, 0.3042658859699344)]\n",
      "[(48, 0.12695201721908841), (109, 0.14526797021382454), (121, 0.11308151590243759), (130, 0.2905359404276491), (137, 0.1723003568352141), (139, 0.225001067596466), (321, 0.18513451890514523), (379, 0.18513451890514523), (428, 0.225001067596466), (429, 0.675003202789398), (430, 0.26486761628778677), (431, 0.26486761628778677), (432, 0.26486761628778677)]\n",
      "[(6, 0.23715912781024845), (33, 0.13155628383463136), (200, 0.29558862756527854), (245, 0.2525280965614786), (341, 0.2525280965614786), (412, 0.32976769385786703), (433, 0.3881971936128971), (434, 0.3881971936128971), (435, 0.3881971936128971), (436, 0.3881971936128971)]\n",
      "[(33, 0.16846554875302183), (38, 0.422286901753907), (188, 0.3474644953079407), (437, 0.422286901753907), (438, 0.49710930819987337), (439, 0.49710930819987337)]\n",
      "[(0, 0.4576334838262421), (12, 0.24379603979895814), (24, 0.17599086914121065), (90, 0.4576334838262421), (125, 0.42590875558654284), (440, 0.556179490662953)]\n",
      "[(22, 0.15577865527682877), (24, 0.15148436933027482), (441, 0.5635558228512806), (442, 0.5635558228512806), (443, 0.5635558228512806)]\n",
      "[(6, 0.27837014570573937), (113, 0.387071253954465), (444, 0.4556540173947779), (445, 0.387071253954465), (446, 0.4556540173947779), (447, 0.4556540173947779)]\n",
      "[(116, 0.29195046497914495), (151, 0.29195046497914495), (267, 0.29195046497914495), (409, 0.2616909990504567), (448, 0.29195046497914495), (449, 0.34367936365450236), (450, 0.34367936365450236), (451, 0.34367936365450236), (452, 0.34367936365450236), (453, 0.34367936365450236)]\n",
      "[(12, 0.17565018932440168), (22, 0.13039238798976327), (24, 0.0633989574020795), (127, 0.16485790364263425), (130, 0.38807305915989565), (135, 0.28818321556083754), (297, 0.15342938633332195), (355, 0.16485790364263425), (428, 0.20035812089863667), (454, 0.4717166763092782), (455, 0.2358583381546391), (456, 0.2358583381546391), (457, 0.2358583381546391), (458, 0.2358583381546391), (459, 0.20035812089863667), (460, 0.2358583381546391), (461, 0.2358583381546391)]\n",
      "[(12, 0.07697099380788759), (22, 0.1142774935473578), (24, 0.05556362650551459), (34, 0.3511926458460477), (40, 0.17559632292302385), (48, 0.09907645172294495), (49, 0.12628365836545571), (109, 0.11337066832850708), (127, 0.14448349562576546), (223, 0.17559632292302385), (254, 0.17559632292302385), (282, 0.17559632292302385), (323, 0.17559632292302385), (462, 0.20670915022028227), (463, 0.20670915022028227), (464, 0.20670915022028227), (465, 0.20670915022028227), (466, 0.20670915022028227), (467, 0.20670915022028227), (468, 0.20670915022028227), (469, 0.20670915022028227), (470, 0.20670915022028227), (471, 0.20670915022028227), (472, 0.20670915022028227), (473, 0.20670915022028227), (474, 0.20670915022028227), (475, 0.20670915022028227), (476, 0.20670915022028227)]\n",
      "[(0, 0.3998017392501095), (10, 0.3720861065970481), (245, 0.3720861065970481), (339, 0.4858943577361062), (477, 0.5719869762221029)]\n",
      "[(248, 0.319525711572494), (404, 0.4172575585382552), (478, 0.4911888467404995), (479, 0.4911888467404995), (480, 0.4911888467404995)]\n",
      "[(12, 0.07156713290534403), (24, 0.1549881031579807), (30, 0.14634623578295566), (138, 0.16326832691919796), (140, 0.13433982104851333), (168, 0.14634623578295566), (192, 0.12502692226562595), (200, 0.14634623578295566), (227, 0.14634623578295566), (324, 0.16326832691919796), (408, 0.3265366538383959), (459, 0.16326832691919796), (481, 0.19219683278988264), (482, 0.19219683278988264), (483, 0.19219683278988264), (484, 0.19219683278988264), (485, 0.19219683278988264), (486, 0.19219683278988264), (487, 0.19219683278988264), (488, 0.19219683278988264), (489, 0.19219683278988264), (490, 0.3843936655797653), (491, 0.19219683278988264), (492, 0.19219683278988264), (493, 0.19219683278988264), (494, 0.19219683278988264), (495, 0.19219683278988264)]\n",
      "[(496, 1.0)]\n",
      "[(22, 0.13717881951103902), (24, 0.13339726756642714), (110, 0.3228296132924663), (127, 0.34687627027026496), (497, 0.4962677484275988), (498, 0.4962677484275988), (499, 0.4962677484275988)]\n",
      "[(354, 0.5149221706656895), (500, 0.6061580479367301), (501, 0.6061580479367301)]\n",
      "[(184, 0.44308246393491596), (502, 0.633907694445084), (503, 0.633907694445084)]\n",
      "[(0, 0.21246907261576872), (4, 0.17553038533706625), (12, 0.1131890919571549), (47, 0.18570544450926307), (379, 0.21246907261576872), (504, 0.6079490430139477), (505, 0.30397452150697385), (506, 0.30397452150697385), (507, 0.30397452150697385), (508, 0.30397452150697385), (509, 0.30397452150697385)]\n",
      "[(24, 0.16341746849872468), (188, 0.42493855386969365), (192, 0.39548035070813164), (445, 0.516444090756336), (510, 0.6079496276429786)]\n",
      "[(24, 0.11726381348835099), (121, 0.18624983235895687), (511, 0.436247681482075), (512, 0.436247681482075), (513, 0.436247681482075), (514, 0.436247681482075), (515, 0.436247681482075)]\n",
      "[(24, 0.15335654798574472), (516, 0.5705207472680539), (517, 0.5705207472680539), (518, 0.5705207472680539)]\n",
      "[(18, 0.38545953445275805), (22, 0.13993117214696335), (33, 0.17155471893123853), (47, 0.30926510180697714), (106, 0.2923200374385251), (109, 0.277641555022702), (112, 0.3538359876684828), (128, 0.23307066916119631), (192, 0.32930685912580315), (519, 0.5062248529600446)]\n",
      "[(4, 0.0917495180101128), (12, 0.05916380010862038), (24, 0.08541802903278703), (97, 0.07944355554755957), (102, 0.08714243154907983), (106, 0.0917495180101128), (110, 0.20671689745914534), (130, 0.17428486309815966), (135, 0.1941360180217264), (148, 0.134972217913106), (225, 0.134972217913106), (236, 0.11105732473109291), (263, 0.11105732473109291), (274, 0.134972217913106), (291, 0.539888871652424), (297, 0.10335844872957267), (416, 0.134972217913106), (429, 0.134972217913106), (437, 0.134972217913106), (440, 0.134972217913106), (520, 0.15888711109511913), (521, 0.15888711109511913), (522, 0.15888711109511913), (523, 0.15888711109511913), (524, 0.15888711109511913), (525, 0.15888711109511913), (526, 0.15888711109511913), (527, 0.15888711109511913), (528, 0.12098290219287632), (529, 0.15888711109511913), (530, 0.15888711109511913), (531, 0.15888711109511913), (532, 0.15888711109511913), (533, 0.15888711109511913), (534, 0.15888711109511913), (535, 0.15888711109511913)]\n",
      "[(204, 0.5055282082622798), (341, 0.47048325287454806), (536, 0.723247357005688)]\n",
      "[(4, 0.27833825045812494), (22, 0.13323820693657135), (24, 0.12956528423368247), (106, 0.27833825045812494), (112, 0.33691186762207437), (537, 0.48201191114362807), (538, 0.48201191114362807), (539, 0.48201191114362807)]\n",
      "[(97, 0.284164878526736), (109, 0.1558516503005974), (142, 0.43274865366353527), (145, 0.21637432683176763), (147, 0.21637432683176763), (271, 0.36970703067749505), (297, 0.18485351533874753), (355, 0.1986227263759769), (540, 0.284164878526736), (541, 0.284164878526736), (542, 0.284164878526736), (543, 0.284164878526736), (544, 0.284164878526736)]\n",
      "[(15, 0.16603578489441181), (22, 0.10805552770725918), (33, 0.06623769171788427), (49, 0.2388160069301424), (121, 0.16689323700085446), (130, 0.21439615120163308), (135, 0.1194080034650712), (137, 0.1271461744174024), (140, 0.13661693024761415), (142, 0.14882685811186888), (263, 0.13661693024761415), (306, 0.16603578489441181), (337, 0.14882685811186888), (355, 0.2732338604952283), (545, 0.19545463954120948), (546, 0.19545463954120948), (547, 0.19545463954120948), (548, 0.19545463954120948), (549, 0.19545463954120948), (550, 0.19545463954120948), (551, 0.19545463954120948), (552, 0.19545463954120948), (553, 0.19545463954120948), (554, 0.19545463954120948), (555, 0.19545463954120948), (556, 0.19545463954120948), (557, 0.19545463954120948), (558, 0.19545463954120948), (559, 0.19545463954120948), (560, 0.19545463954120948)]\n",
      "[(22, 0.220479342200188), (24, 0.21440147909992435), (297, 0.5188648002305944), (561, 0.7976215797634882)]\n",
      "[(205, 0.24426864849286758), (224, 0.29686903888194144), (226, 0.29686903888194144), (227, 0.26609978298103976), (228, 0.5937380777638829), (379, 0.24426864849286758), (448, 0.29686903888194144), (528, 0.26609978298103976), (562, 0.3494694292710153)]\n",
      "[(12, 0.21292494707699622), (22, 0.0790314898570579), (130, 0.1568087039007243), (171, 0.24287615318193134), (528, 0.2177030380008183), (563, 0.2859098778225349), (564, 0.2859098778225349), (565, 0.2859098778225349), (566, 0.2859098778225349), (567, 0.2859098778225349), (568, 0.2859098778225349), (569, 0.2859098778225349), (570, 0.2859098778225349), (571, 0.2859098778225349), (572, 0.2859098778225349)]\n",
      "[(90, 0.292224141194661), (102, 0.22929709753682617), (221, 0.35515118485249597), (233, 0.35515118485249597), (236, 0.292224141194661), (573, 0.41807822851033094), (574, 0.41807822851033094), (575, 0.41807822851033094)]\n",
      "[(12, 0.20793024188952056), (229, 0.3903092153063807), (230, 0.4251925006723099), (576, 0.5584062447388597), (577, 0.5584062447388597)]\n",
      "[(47, 0.5213339821021504), (578, 0.8533527284221425)]\n"
     ]
    }
   ],
   "source": [
    "from gensim import models\n",
    "tfidf = models.TfidfModel(corpus)\n",
    "\n",
    "for document in tfidf[corpus]:\n",
    "       print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a1e423",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
